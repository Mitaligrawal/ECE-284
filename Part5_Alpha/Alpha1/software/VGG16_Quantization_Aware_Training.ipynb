{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): QuantConv2d(\n",
      "      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (33): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (41): ReLU(inplace=True)\n",
      "    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "     \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, './misc')\n",
    "from models import *\n",
    "\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"final_VGG16_quant\"\n",
    "model = final_VGG16_quant()\n",
    "\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d354a1-9d41-42cc-9ff6-5152d325891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.743 (0.743)\tData 0.306 (0.306)\tLoss 2.5791 (2.5791)\tPrec 9.375% (9.375%)\n",
      "Epoch: [0][100/391]\tTime 0.021 (0.028)\tData 0.001 (0.004)\tLoss 1.7758 (2.0248)\tPrec 28.906% (26.106%)\n",
      "Epoch: [0][200/391]\tTime 0.021 (0.024)\tData 0.001 (0.003)\tLoss 1.4695 (1.8586)\tPrec 45.312% (31.926%)\n",
      "Epoch: [0][300/391]\tTime 0.020 (0.023)\tData 0.001 (0.002)\tLoss 1.6487 (1.7344)\tPrec 37.500% (36.496%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.250 (0.250)\tLoss 1.3022 (1.3022)\tPrec 56.250% (56.250%)\n",
      " * Prec 52.950% \n",
      "best acc: 52.950000\n",
      "Epoch: [1][0/391]\tTime 0.352 (0.352)\tData 0.331 (0.331)\tLoss 1.2386 (1.2386)\tPrec 48.438% (48.438%)\n",
      "Epoch: [1][100/391]\tTime 0.018 (0.025)\tData 0.001 (0.006)\tLoss 1.5457 (1.2643)\tPrec 42.969% (53.968%)\n",
      "Epoch: [1][200/391]\tTime 0.019 (0.023)\tData 0.001 (0.004)\tLoss 0.9439 (1.2208)\tPrec 64.844% (56.017%)\n",
      "Epoch: [1][300/391]\tTime 0.018 (0.022)\tData 0.001 (0.003)\tLoss 1.0101 (1.1894)\tPrec 65.625% (57.389%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.191 (0.191)\tLoss 0.9986 (0.9986)\tPrec 62.500% (62.500%)\n",
      " * Prec 60.000% \n",
      "best acc: 60.000000\n",
      "Epoch: [2][0/391]\tTime 0.322 (0.322)\tData 0.299 (0.299)\tLoss 1.0368 (1.0368)\tPrec 68.750% (68.750%)\n",
      "Epoch: [2][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.8784 (1.0367)\tPrec 65.625% (63.057%)\n",
      "Epoch: [2][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.8969 (1.0008)\tPrec 66.406% (64.373%)\n",
      "Epoch: [2][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.8804 (0.9804)\tPrec 67.188% (65.192%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 0.7445 (0.7445)\tPrec 69.531% (69.531%)\n",
      " * Prec 67.990% \n",
      "best acc: 67.990000\n",
      "Epoch: [3][0/391]\tTime 0.388 (0.388)\tData 0.366 (0.366)\tLoss 1.0043 (1.0043)\tPrec 64.062% (64.062%)\n",
      "Epoch: [3][100/391]\tTime 0.021 (0.026)\tData 0.001 (0.006)\tLoss 0.9652 (0.8660)\tPrec 62.500% (69.106%)\n",
      "Epoch: [3][200/391]\tTime 0.021 (0.023)\tData 0.002 (0.004)\tLoss 0.9788 (0.8654)\tPrec 64.844% (69.026%)\n",
      "Epoch: [3][300/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.8837 (0.8526)\tPrec 69.531% (69.643%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.8932 (0.8932)\tPrec 70.312% (70.312%)\n",
      " * Prec 67.570% \n",
      "best acc: 67.990000\n",
      "Epoch: [4][0/391]\tTime 0.309 (0.309)\tData 0.285 (0.285)\tLoss 0.7523 (0.7523)\tPrec 74.219% (74.219%)\n",
      "Epoch: [4][100/391]\tTime 0.021 (0.025)\tData 0.002 (0.006)\tLoss 0.9098 (0.7965)\tPrec 67.188% (72.030%)\n",
      "Epoch: [4][200/391]\tTime 0.021 (0.023)\tData 0.002 (0.004)\tLoss 0.7407 (0.7751)\tPrec 75.000% (72.956%)\n",
      "Epoch: [4][300/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 1.0573 (0.7693)\tPrec 64.844% (73.194%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.6859 (0.6859)\tPrec 80.469% (80.469%)\n",
      " * Prec 73.370% \n",
      "best acc: 73.370000\n",
      "Epoch: [5][0/391]\tTime 0.287 (0.287)\tData 0.263 (0.263)\tLoss 0.9251 (0.9251)\tPrec 60.938% (60.938%)\n",
      "Epoch: [5][100/391]\tTime 0.020 (0.025)\tData 0.001 (0.005)\tLoss 0.6752 (0.7176)\tPrec 72.656% (75.085%)\n",
      "Epoch: [5][200/391]\tTime 0.020 (0.023)\tData 0.001 (0.003)\tLoss 0.7273 (0.7028)\tPrec 74.219% (75.704%)\n",
      "Epoch: [5][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.6467 (0.6997)\tPrec 74.219% (75.831%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 0.6206 (0.6206)\tPrec 80.469% (80.469%)\n",
      " * Prec 77.090% \n",
      "best acc: 77.090000\n",
      "Epoch: [6][0/391]\tTime 0.368 (0.368)\tData 0.342 (0.342)\tLoss 0.6353 (0.6353)\tPrec 79.688% (79.688%)\n",
      "Epoch: [6][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.5207 (0.6482)\tPrec 82.812% (77.731%)\n",
      "Epoch: [6][200/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.8391 (0.6468)\tPrec 72.656% (77.670%)\n",
      "Epoch: [6][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.6056 (0.6475)\tPrec 80.469% (77.655%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.6375 (0.6375)\tPrec 78.906% (78.906%)\n",
      " * Prec 76.700% \n",
      "best acc: 77.090000\n",
      "Epoch: [7][0/391]\tTime 0.328 (0.328)\tData 0.305 (0.305)\tLoss 0.5685 (0.5685)\tPrec 78.906% (78.906%)\n",
      "Epoch: [7][100/391]\tTime 0.021 (0.024)\tData 0.002 (0.005)\tLoss 0.6095 (0.6069)\tPrec 78.125% (79.146%)\n",
      "Epoch: [7][200/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.5858 (0.6023)\tPrec 79.688% (79.396%)\n",
      "Epoch: [7][300/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.6502 (0.6043)\tPrec 76.562% (79.399%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 0.5380 (0.5380)\tPrec 80.469% (80.469%)\n",
      " * Prec 79.250% \n",
      "best acc: 79.250000\n",
      "Epoch: [8][0/391]\tTime 0.378 (0.378)\tData 0.355 (0.355)\tLoss 0.5200 (0.5200)\tPrec 82.031% (82.031%)\n",
      "Epoch: [8][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.6008 (0.5655)\tPrec 79.688% (80.732%)\n",
      "Epoch: [8][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.3746 (0.5650)\tPrec 90.625% (80.741%)\n",
      "Epoch: [8][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.5080 (0.5628)\tPrec 84.375% (80.762%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.8274 (0.8274)\tPrec 73.438% (73.438%)\n",
      " * Prec 76.040% \n",
      "best acc: 79.250000\n",
      "Epoch: [9][0/391]\tTime 0.304 (0.304)\tData 0.282 (0.282)\tLoss 0.4598 (0.4598)\tPrec 81.250% (81.250%)\n",
      "Epoch: [9][100/391]\tTime 0.021 (0.023)\tData 0.002 (0.004)\tLoss 0.4523 (0.5523)\tPrec 82.812% (80.716%)\n",
      "Epoch: [9][200/391]\tTime 0.020 (0.022)\tData 0.002 (0.003)\tLoss 0.4381 (0.5446)\tPrec 84.375% (81.192%)\n",
      "Epoch: [9][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.002)\tLoss 0.5210 (0.5442)\tPrec 83.594% (81.377%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.5068 (0.5068)\tPrec 82.031% (82.031%)\n",
      " * Prec 79.610% \n",
      "best acc: 79.610000\n",
      "Epoch: [10][0/391]\tTime 0.353 (0.353)\tData 0.330 (0.330)\tLoss 0.4799 (0.4799)\tPrec 85.938% (85.938%)\n",
      "Epoch: [10][100/391]\tTime 0.021 (0.024)\tData 0.002 (0.005)\tLoss 0.3815 (0.5167)\tPrec 86.719% (82.163%)\n",
      "Epoch: [10][200/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.4889 (0.5112)\tPrec 82.812% (82.591%)\n",
      "Epoch: [10][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.5007 (0.5121)\tPrec 82.812% (82.548%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.5801 (0.5801)\tPrec 81.250% (81.250%)\n",
      " * Prec 78.690% \n",
      "best acc: 79.610000\n",
      "Epoch: [11][0/391]\tTime 0.308 (0.308)\tData 0.286 (0.286)\tLoss 0.4510 (0.4510)\tPrec 84.375% (84.375%)\n",
      "Epoch: [11][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.5490 (0.4826)\tPrec 83.594% (83.594%)\n",
      "Epoch: [11][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.4095 (0.4808)\tPrec 83.594% (83.590%)\n",
      "Epoch: [11][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.5860 (0.4844)\tPrec 79.688% (83.464%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 0.5272 (0.5272)\tPrec 79.688% (79.688%)\n",
      " * Prec 80.610% \n",
      "best acc: 80.610000\n",
      "Epoch: [12][0/391]\tTime 0.356 (0.356)\tData 0.333 (0.333)\tLoss 0.4696 (0.4696)\tPrec 85.938% (85.938%)\n",
      "Epoch: [12][100/391]\tTime 0.021 (0.024)\tData 0.001 (0.005)\tLoss 0.4436 (0.4600)\tPrec 82.031% (84.336%)\n",
      "Epoch: [12][200/391]\tTime 0.021 (0.023)\tData 0.002 (0.003)\tLoss 0.5268 (0.4610)\tPrec 82.031% (84.282%)\n",
      "Epoch: [12][300/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.6446 (0.4634)\tPrec 78.906% (84.269%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.5679 (0.5679)\tPrec 78.125% (78.125%)\n",
      " * Prec 79.260% \n",
      "best acc: 80.610000\n",
      "Epoch: [13][0/391]\tTime 0.400 (0.400)\tData 0.374 (0.374)\tLoss 0.4644 (0.4644)\tPrec 82.031% (82.031%)\n",
      "Epoch: [13][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.5199 (0.4261)\tPrec 82.812% (85.628%)\n",
      "Epoch: [13][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.4393 (0.4369)\tPrec 82.812% (85.277%)\n",
      "Epoch: [13][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.3786 (0.4380)\tPrec 85.156% (85.156%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.5065 (0.5065)\tPrec 84.375% (84.375%)\n",
      " * Prec 80.910% \n",
      "best acc: 80.910000\n",
      "Epoch: [14][0/391]\tTime 0.358 (0.358)\tData 0.337 (0.337)\tLoss 0.3949 (0.3949)\tPrec 85.938% (85.938%)\n",
      "Epoch: [14][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.3513 (0.4139)\tPrec 83.594% (85.651%)\n",
      "Epoch: [14][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.6133 (0.4215)\tPrec 79.688% (85.576%)\n",
      "Epoch: [14][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.4780 (0.4232)\tPrec 84.375% (85.631%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 0.7413 (0.7413)\tPrec 77.344% (77.344%)\n",
      " * Prec 78.600% \n",
      "best acc: 80.910000\n",
      "Epoch: [15][0/391]\tTime 0.322 (0.322)\tData 0.299 (0.299)\tLoss 0.4373 (0.4373)\tPrec 86.719% (86.719%)\n",
      "Epoch: [15][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.004)\tLoss 0.4290 (0.3935)\tPrec 85.156% (86.371%)\n",
      "Epoch: [15][200/391]\tTime 0.020 (0.022)\tData 0.002 (0.003)\tLoss 0.3628 (0.3997)\tPrec 89.062% (86.276%)\n",
      "Epoch: [15][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.4227 (0.4023)\tPrec 83.594% (86.293%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.230 (0.230)\tLoss 0.3290 (0.3290)\tPrec 85.156% (85.156%)\n",
      " * Prec 84.790% \n",
      "best acc: 84.790000\n",
      "Epoch: [16][0/391]\tTime 0.412 (0.412)\tData 0.388 (0.388)\tLoss 0.2732 (0.2732)\tPrec 89.062% (89.062%)\n",
      "Epoch: [16][100/391]\tTime 0.020 (0.025)\tData 0.001 (0.005)\tLoss 0.4116 (0.3801)\tPrec 87.500% (87.067%)\n",
      "Epoch: [16][200/391]\tTime 0.021 (0.023)\tData 0.001 (0.003)\tLoss 0.3257 (0.3844)\tPrec 91.406% (86.831%)\n",
      "Epoch: [16][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.4769 (0.3887)\tPrec 82.031% (86.675%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.195 (0.195)\tLoss 0.4817 (0.4817)\tPrec 85.156% (85.156%)\n",
      " * Prec 84.590% \n",
      "best acc: 84.790000\n",
      "Epoch: [17][0/391]\tTime 0.276 (0.276)\tData 0.252 (0.252)\tLoss 0.5246 (0.5246)\tPrec 82.031% (82.031%)\n",
      "Epoch: [17][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.3631 (0.3673)\tPrec 87.500% (87.477%)\n",
      "Epoch: [17][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.3666 (0.3696)\tPrec 87.500% (87.364%)\n",
      "Epoch: [17][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.3906 (0.3767)\tPrec 87.500% (87.139%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.3563 (0.3563)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.000% \n",
      "best acc: 84.790000\n",
      "Epoch: [18][0/391]\tTime 0.328 (0.328)\tData 0.301 (0.301)\tLoss 0.2177 (0.2177)\tPrec 93.750% (93.750%)\n",
      "Epoch: [18][100/391]\tTime 0.021 (0.024)\tData 0.001 (0.005)\tLoss 0.3371 (0.3428)\tPrec 89.062% (88.227%)\n",
      "Epoch: [18][200/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.2366 (0.3522)\tPrec 91.406% (87.990%)\n",
      "Epoch: [18][300/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.4188 (0.3578)\tPrec 85.938% (87.926%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.4840 (0.4840)\tPrec 85.156% (85.156%)\n",
      " * Prec 82.110% \n",
      "best acc: 84.790000\n",
      "Epoch: [19][0/391]\tTime 0.313 (0.313)\tData 0.287 (0.287)\tLoss 0.3541 (0.3541)\tPrec 87.500% (87.500%)\n",
      "Epoch: [19][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.3485 (0.3425)\tPrec 87.500% (88.390%)\n",
      "Epoch: [19][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.4093 (0.3470)\tPrec 83.594% (88.196%)\n",
      "Epoch: [19][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.4351 (0.3510)\tPrec 83.594% (88.087%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.308 (0.308)\tLoss 0.3683 (0.3683)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.530% \n",
      "best acc: 85.530000\n",
      "Epoch: [20][0/391]\tTime 0.366 (0.366)\tData 0.344 (0.344)\tLoss 0.2454 (0.2454)\tPrec 92.188% (92.188%)\n",
      "Epoch: [20][100/391]\tTime 0.018 (0.024)\tData 0.001 (0.005)\tLoss 0.2607 (0.3326)\tPrec 90.625% (88.420%)\n",
      "Epoch: [20][200/391]\tTime 0.018 (0.022)\tData 0.001 (0.003)\tLoss 0.4002 (0.3374)\tPrec 85.938% (88.413%)\n",
      "Epoch: [20][300/391]\tTime 0.019 (0.021)\tData 0.001 (0.002)\tLoss 0.2603 (0.3394)\tPrec 89.844% (88.375%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.3558 (0.3558)\tPrec 86.719% (86.719%)\n",
      " * Prec 83.470% \n",
      "best acc: 85.530000\n",
      "Epoch: [21][0/391]\tTime 0.362 (0.362)\tData 0.340 (0.340)\tLoss 0.3329 (0.3329)\tPrec 90.625% (90.625%)\n",
      "Epoch: [21][100/391]\tTime 0.021 (0.024)\tData 0.001 (0.005)\tLoss 0.3584 (0.3337)\tPrec 89.062% (88.645%)\n",
      "Epoch: [21][200/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.4405 (0.3268)\tPrec 86.719% (89.008%)\n",
      "Epoch: [21][300/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.2172 (0.3313)\tPrec 93.750% (88.831%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.3247 (0.3247)\tPrec 89.062% (89.062%)\n",
      " * Prec 84.300% \n",
      "best acc: 85.530000\n",
      "Epoch: [22][0/391]\tTime 0.396 (0.396)\tData 0.371 (0.371)\tLoss 0.2414 (0.2414)\tPrec 90.625% (90.625%)\n",
      "Epoch: [22][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.3533 (0.2952)\tPrec 88.281% (89.666%)\n",
      "Epoch: [22][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2909 (0.3074)\tPrec 91.406% (89.459%)\n",
      "Epoch: [22][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.3399 (0.3102)\tPrec 90.625% (89.395%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.4021 (0.4021)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.730% \n",
      "best acc: 85.530000\n",
      "Epoch: [23][0/391]\tTime 0.355 (0.355)\tData 0.330 (0.330)\tLoss 0.2452 (0.2452)\tPrec 90.625% (90.625%)\n",
      "Epoch: [23][100/391]\tTime 0.019 (0.024)\tData 0.002 (0.005)\tLoss 0.2264 (0.3073)\tPrec 91.406% (89.898%)\n",
      "Epoch: [23][200/391]\tTime 0.019 (0.022)\tData 0.001 (0.003)\tLoss 0.3041 (0.3105)\tPrec 89.844% (89.700%)\n",
      "Epoch: [23][300/391]\tTime 0.018 (0.021)\tData 0.001 (0.002)\tLoss 0.3099 (0.3119)\tPrec 89.844% (89.644%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.277 (0.277)\tLoss 0.4055 (0.4055)\tPrec 84.375% (84.375%)\n",
      " * Prec 83.760% \n",
      "best acc: 85.530000\n",
      "Epoch: [24][0/391]\tTime 0.335 (0.335)\tData 0.312 (0.312)\tLoss 0.3712 (0.3712)\tPrec 85.156% (85.156%)\n",
      "Epoch: [24][100/391]\tTime 0.021 (0.024)\tData 0.002 (0.005)\tLoss 0.2435 (0.2926)\tPrec 91.406% (90.068%)\n",
      "Epoch: [24][200/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.3556 (0.2957)\tPrec 88.281% (89.898%)\n",
      "Epoch: [24][300/391]\tTime 0.021 (0.021)\tData 0.002 (0.002)\tLoss 0.2025 (0.2976)\tPrec 94.531% (89.823%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.4024 (0.4024)\tPrec 85.938% (85.938%)\n",
      " * Prec 85.730% \n",
      "best acc: 85.730000\n",
      "Epoch: [25][0/391]\tTime 0.340 (0.340)\tData 0.319 (0.319)\tLoss 0.2340 (0.2340)\tPrec 91.406% (91.406%)\n",
      "Epoch: [25][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.3043 (0.2727)\tPrec 89.844% (90.903%)\n",
      "Epoch: [25][200/391]\tTime 0.020 (0.022)\tData 0.002 (0.003)\tLoss 0.3425 (0.2876)\tPrec 86.719% (90.330%)\n",
      "Epoch: [25][300/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.2114 (0.2929)\tPrec 94.531% (90.015%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 0.3631 (0.3631)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.450% \n",
      "best acc: 86.450000\n",
      "Epoch: [26][0/391]\tTime 0.342 (0.342)\tData 0.320 (0.320)\tLoss 0.2756 (0.2756)\tPrec 90.625% (90.625%)\n",
      "Epoch: [26][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.2341 (0.2810)\tPrec 92.188% (90.432%)\n",
      "Epoch: [26][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.3135 (0.2783)\tPrec 89.062% (90.594%)\n",
      "Epoch: [26][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.2105 (0.2778)\tPrec 92.188% (90.480%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.3823 (0.3823)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.410% \n",
      "best acc: 86.450000\n",
      "Epoch: [27][0/391]\tTime 0.418 (0.418)\tData 0.393 (0.393)\tLoss 0.2108 (0.2108)\tPrec 90.625% (90.625%)\n",
      "Epoch: [27][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.3648 (0.2676)\tPrec 89.062% (90.958%)\n",
      "Epoch: [27][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.3018 (0.2710)\tPrec 90.625% (90.780%)\n",
      "Epoch: [27][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2363 (0.2723)\tPrec 92.969% (90.760%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 0.3551 (0.3551)\tPrec 87.500% (87.500%)\n",
      " * Prec 85.910% \n",
      "best acc: 86.450000\n",
      "Epoch: [28][0/391]\tTime 0.306 (0.306)\tData 0.282 (0.282)\tLoss 0.2251 (0.2251)\tPrec 91.406% (91.406%)\n",
      "Epoch: [28][100/391]\tTime 0.021 (0.023)\tData 0.001 (0.004)\tLoss 0.2626 (0.2453)\tPrec 92.188% (91.785%)\n",
      "Epoch: [28][200/391]\tTime 0.021 (0.021)\tData 0.001 (0.003)\tLoss 0.2671 (0.2519)\tPrec 94.531% (91.356%)\n",
      "Epoch: [28][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.1848 (0.2534)\tPrec 92.188% (91.360%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.3053 (0.3053)\tPrec 91.406% (91.406%)\n",
      " * Prec 85.250% \n",
      "best acc: 86.450000\n",
      "Epoch: [29][0/391]\tTime 0.301 (0.301)\tData 0.279 (0.279)\tLoss 0.3254 (0.3254)\tPrec 88.281% (88.281%)\n",
      "Epoch: [29][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.2258 (0.2395)\tPrec 91.406% (91.909%)\n",
      "Epoch: [29][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2934 (0.2517)\tPrec 87.500% (91.379%)\n",
      "Epoch: [29][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.2821 (0.2553)\tPrec 89.844% (91.271%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.3592 (0.3592)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.360% \n",
      "best acc: 87.360000\n",
      "Epoch: [30][0/391]\tTime 0.359 (0.359)\tData 0.336 (0.336)\tLoss 0.2583 (0.2583)\tPrec 92.188% (92.188%)\n",
      "Epoch: [30][100/391]\tTime 0.021 (0.024)\tData 0.002 (0.005)\tLoss 0.3061 (0.2454)\tPrec 89.844% (91.770%)\n",
      "Epoch: [30][200/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.2618 (0.2529)\tPrec 92.969% (91.395%)\n",
      "Epoch: [30][300/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.3543 (0.2510)\tPrec 85.938% (91.466%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.4396 (0.4396)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.760% \n",
      "best acc: 87.360000\n",
      "Epoch: [31][0/391]\tTime 0.405 (0.405)\tData 0.378 (0.378)\tLoss 0.2094 (0.2094)\tPrec 91.406% (91.406%)\n",
      "Epoch: [31][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.1808 (0.2245)\tPrec 94.531% (92.319%)\n",
      "Epoch: [31][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.3192 (0.2364)\tPrec 85.156% (91.892%)\n",
      "Epoch: [31][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1974 (0.2386)\tPrec 93.750% (91.783%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.2548 (0.2548)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.030% \n",
      "best acc: 87.360000\n",
      "Epoch: [32][0/391]\tTime 0.315 (0.315)\tData 0.291 (0.291)\tLoss 0.1527 (0.1527)\tPrec 94.531% (94.531%)\n",
      "Epoch: [32][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.2744 (0.2201)\tPrec 91.406% (92.489%)\n",
      "Epoch: [32][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.1796 (0.2341)\tPrec 93.750% (92.009%)\n",
      "Epoch: [32][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.2441 (0.2383)\tPrec 92.188% (91.866%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.2738 (0.2738)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.330% \n",
      "best acc: 87.360000\n",
      "Epoch: [33][0/391]\tTime 0.298 (0.298)\tData 0.273 (0.273)\tLoss 0.1369 (0.1369)\tPrec 97.656% (97.656%)\n",
      "Epoch: [33][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1373 (0.2154)\tPrec 93.750% (92.597%)\n",
      "Epoch: [33][200/391]\tTime 0.020 (0.022)\tData 0.002 (0.003)\tLoss 0.1413 (0.2232)\tPrec 96.094% (92.324%)\n",
      "Epoch: [33][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.1844 (0.2300)\tPrec 92.969% (92.112%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 0.3492 (0.3492)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.530% \n",
      "best acc: 87.360000\n",
      "Epoch: [34][0/391]\tTime 0.400 (0.400)\tData 0.376 (0.376)\tLoss 0.1864 (0.1864)\tPrec 94.531% (94.531%)\n",
      "Epoch: [34][100/391]\tTime 0.021 (0.024)\tData 0.002 (0.005)\tLoss 0.2225 (0.2109)\tPrec 92.188% (92.613%)\n",
      "Epoch: [34][200/391]\tTime 0.021 (0.023)\tData 0.001 (0.003)\tLoss 0.1829 (0.2180)\tPrec 92.969% (92.460%)\n",
      "Epoch: [34][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.1570 (0.2209)\tPrec 94.531% (92.369%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.3607 (0.3607)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.150% \n",
      "best acc: 87.360000\n",
      "Epoch: [35][0/391]\tTime 0.300 (0.300)\tData 0.279 (0.279)\tLoss 0.2901 (0.2901)\tPrec 90.625% (90.625%)\n",
      "Epoch: [35][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.2880 (0.1990)\tPrec 87.500% (93.131%)\n",
      "Epoch: [35][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.2521 (0.2168)\tPrec 90.625% (92.471%)\n",
      "Epoch: [35][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.2608 (0.2175)\tPrec 90.625% (92.553%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.2149 (0.2149)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.640% \n",
      "best acc: 87.640000\n",
      "Epoch: [36][0/391]\tTime 0.363 (0.363)\tData 0.342 (0.342)\tLoss 0.1701 (0.1701)\tPrec 92.969% (92.969%)\n",
      "Epoch: [36][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.3164 (0.2185)\tPrec 85.938% (92.342%)\n",
      "Epoch: [36][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1947 (0.2113)\tPrec 92.969% (92.654%)\n",
      "Epoch: [36][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.003)\tLoss 0.1284 (0.2131)\tPrec 96.875% (92.624%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.4657 (0.4657)\tPrec 84.375% (84.375%)\n",
      " * Prec 86.250% \n",
      "best acc: 87.640000\n",
      "Epoch: [37][0/391]\tTime 0.324 (0.324)\tData 0.300 (0.300)\tLoss 0.2231 (0.2231)\tPrec 91.406% (91.406%)\n",
      "Epoch: [37][100/391]\tTime 0.021 (0.024)\tData 0.002 (0.004)\tLoss 0.2075 (0.2031)\tPrec 93.750% (93.100%)\n",
      "Epoch: [37][200/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.2252 (0.2094)\tPrec 92.188% (93.000%)\n",
      "Epoch: [37][300/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.1696 (0.2108)\tPrec 94.531% (92.901%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.3721 (0.3721)\tPrec 84.375% (84.375%)\n",
      " * Prec 87.780% \n",
      "best acc: 87.780000\n",
      "Epoch: [38][0/391]\tTime 0.366 (0.366)\tData 0.344 (0.344)\tLoss 0.1839 (0.1839)\tPrec 95.312% (95.312%)\n",
      "Epoch: [38][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.2117 (0.1882)\tPrec 93.750% (93.688%)\n",
      "Epoch: [38][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1329 (0.1920)\tPrec 95.312% (93.466%)\n",
      "Epoch: [38][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.2224 (0.1946)\tPrec 93.750% (93.355%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.3605 (0.3605)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.530% \n",
      "best acc: 87.780000\n",
      "Epoch: [39][0/391]\tTime 0.377 (0.377)\tData 0.354 (0.354)\tLoss 0.1795 (0.1795)\tPrec 94.531% (94.531%)\n",
      "Epoch: [39][100/391]\tTime 0.021 (0.024)\tData 0.002 (0.005)\tLoss 0.1856 (0.1926)\tPrec 93.750% (93.325%)\n",
      "Epoch: [39][200/391]\tTime 0.021 (0.023)\tData 0.001 (0.003)\tLoss 0.2422 (0.1965)\tPrec 92.969% (93.295%)\n",
      "Epoch: [39][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.2577 (0.2031)\tPrec 93.750% (93.036%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.3342 (0.3342)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.500% \n",
      "best acc: 87.780000\n",
      "Epoch: [40][0/391]\tTime 0.347 (0.347)\tData 0.323 (0.323)\tLoss 0.2767 (0.2767)\tPrec 91.406% (91.406%)\n",
      "Epoch: [40][100/391]\tTime 0.021 (0.024)\tData 0.001 (0.005)\tLoss 0.0923 (0.1923)\tPrec 96.875% (93.209%)\n",
      "Epoch: [40][200/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.1600 (0.1970)\tPrec 94.531% (93.218%)\n",
      "Epoch: [40][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.1865 (0.2013)\tPrec 94.531% (93.106%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.188 (0.188)\tLoss 0.3392 (0.3392)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.600% \n",
      "best acc: 87.780000\n",
      "Epoch: [41][0/391]\tTime 0.311 (0.311)\tData 0.287 (0.287)\tLoss 0.2360 (0.2360)\tPrec 93.750% (93.750%)\n",
      "Epoch: [41][100/391]\tTime 0.021 (0.024)\tData 0.001 (0.004)\tLoss 0.1614 (0.1921)\tPrec 95.312% (93.448%)\n",
      "Epoch: [41][200/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.1960 (0.1960)\tPrec 92.969% (93.377%)\n",
      "Epoch: [41][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.2438 (0.1978)\tPrec 91.406% (93.301%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.2464 (0.2464)\tPrec 92.188% (92.188%)\n",
      " * Prec 86.070% \n",
      "best acc: 87.780000\n",
      "Epoch: [42][0/391]\tTime 0.418 (0.418)\tData 0.391 (0.391)\tLoss 0.0861 (0.0861)\tPrec 96.094% (96.094%)\n",
      "Epoch: [42][100/391]\tTime 0.021 (0.024)\tData 0.001 (0.005)\tLoss 0.2536 (0.1664)\tPrec 90.625% (94.253%)\n",
      "Epoch: [42][200/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.2638 (0.1801)\tPrec 90.625% (93.781%)\n",
      "Epoch: [42][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.003)\tLoss 0.2554 (0.1833)\tPrec 90.625% (93.740%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.2722 (0.2722)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.300% \n",
      "best acc: 88.300000\n",
      "Epoch: [43][0/391]\tTime 0.369 (0.369)\tData 0.349 (0.349)\tLoss 0.1449 (0.1449)\tPrec 96.094% (96.094%)\n",
      "Epoch: [43][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.005)\tLoss 0.2240 (0.1810)\tPrec 91.406% (93.905%)\n",
      "Epoch: [43][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1043 (0.1808)\tPrec 96.094% (94.003%)\n",
      "Epoch: [43][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1743 (0.1831)\tPrec 93.750% (93.893%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 0.3214 (0.3214)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.160% \n",
      "best acc: 88.300000\n",
      "Epoch: [44][0/391]\tTime 0.324 (0.324)\tData 0.303 (0.303)\tLoss 0.2263 (0.2263)\tPrec 94.531% (94.531%)\n",
      "Epoch: [44][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1207 (0.1798)\tPrec 95.312% (93.866%)\n",
      "Epoch: [44][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.1730 (0.1865)\tPrec 94.531% (93.560%)\n",
      "Epoch: [44][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1428 (0.1866)\tPrec 94.531% (93.644%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 0.2855 (0.2855)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.830% \n",
      "best acc: 88.300000\n",
      "Epoch: [45][0/391]\tTime 0.260 (0.260)\tData 0.212 (0.212)\tLoss 0.1075 (0.1075)\tPrec 96.094% (96.094%)\n",
      "Epoch: [45][100/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2845 (0.1606)\tPrec 91.406% (94.616%)\n",
      "Epoch: [45][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1353 (0.1764)\tPrec 96.094% (93.995%)\n",
      "Epoch: [45][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1692 (0.1805)\tPrec 92.969% (93.856%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.2204 (0.2204)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.280% \n",
      "best acc: 88.300000\n",
      "Epoch: [46][0/391]\tTime 0.306 (0.306)\tData 0.284 (0.284)\tLoss 0.1723 (0.1723)\tPrec 94.531% (94.531%)\n",
      "Epoch: [46][100/391]\tTime 0.021 (0.024)\tData 0.002 (0.005)\tLoss 0.2117 (0.1721)\tPrec 89.844% (94.152%)\n",
      "Epoch: [46][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1849 (0.1700)\tPrec 92.969% (94.271%)\n",
      "Epoch: [46][300/391]\tTime 0.020 (0.022)\tData 0.002 (0.003)\tLoss 0.1974 (0.1770)\tPrec 92.969% (94.067%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 0.3572 (0.3572)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.080% \n",
      "best acc: 88.300000\n",
      "Epoch: [47][0/391]\tTime 0.303 (0.303)\tData 0.280 (0.280)\tLoss 0.2202 (0.2202)\tPrec 89.844% (89.844%)\n",
      "Epoch: [47][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.2170 (0.1720)\tPrec 91.406% (94.261%)\n",
      "Epoch: [47][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1349 (0.1759)\tPrec 94.531% (94.127%)\n",
      "Epoch: [47][300/391]\tTime 0.020 (0.021)\tData 0.002 (0.002)\tLoss 0.1823 (0.1815)\tPrec 93.750% (93.893%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.3632 (0.3632)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.830% \n",
      "best acc: 88.300000\n",
      "Epoch: [48][0/391]\tTime 0.434 (0.434)\tData 0.407 (0.407)\tLoss 0.2487 (0.2487)\tPrec 93.750% (93.750%)\n",
      "Epoch: [48][100/391]\tTime 0.021 (0.025)\tData 0.002 (0.006)\tLoss 0.1544 (0.1567)\tPrec 96.875% (94.879%)\n",
      "Epoch: [48][200/391]\tTime 0.021 (0.023)\tData 0.002 (0.004)\tLoss 0.1373 (0.1685)\tPrec 95.312% (94.422%)\n",
      "Epoch: [48][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.1352 (0.1715)\tPrec 96.094% (94.295%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.2746 (0.2746)\tPrec 89.062% (89.062%)\n",
      " * Prec 88.280% \n",
      "best acc: 88.300000\n",
      "Epoch: [49][0/391]\tTime 0.325 (0.325)\tData 0.303 (0.303)\tLoss 0.2677 (0.2677)\tPrec 88.281% (88.281%)\n",
      "Epoch: [49][100/391]\tTime 0.021 (0.024)\tData 0.002 (0.005)\tLoss 0.2170 (0.1575)\tPrec 92.188% (94.570%)\n",
      "Epoch: [49][200/391]\tTime 0.020 (0.022)\tData 0.002 (0.003)\tLoss 0.1336 (0.1620)\tPrec 94.531% (94.454%)\n",
      "Epoch: [49][300/391]\tTime 0.020 (0.022)\tData 0.002 (0.003)\tLoss 0.2912 (0.1698)\tPrec 92.188% (94.178%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.3709 (0.3709)\tPrec 86.719% (86.719%)\n",
      " * Prec 87.060% \n",
      "best acc: 88.300000\n",
      "Epoch: [50][0/391]\tTime 0.378 (0.378)\tData 0.353 (0.353)\tLoss 0.0738 (0.0738)\tPrec 98.438% (98.438%)\n",
      "Epoch: [50][100/391]\tTime 0.021 (0.024)\tData 0.001 (0.005)\tLoss 0.1064 (0.1616)\tPrec 96.875% (94.609%)\n",
      "Epoch: [50][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2526 (0.1672)\tPrec 92.969% (94.430%)\n",
      "Epoch: [50][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1356 (0.1686)\tPrec 95.312% (94.396%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.4208 (0.4208)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.410% \n",
      "best acc: 88.300000\n",
      "Epoch: [51][0/391]\tTime 0.315 (0.315)\tData 0.293 (0.293)\tLoss 0.2368 (0.2368)\tPrec 91.406% (91.406%)\n",
      "Epoch: [51][100/391]\tTime 0.020 (0.024)\tData 0.002 (0.004)\tLoss 0.1506 (0.1485)\tPrec 94.531% (94.918%)\n",
      "Epoch: [51][200/391]\tTime 0.020 (0.023)\tData 0.001 (0.003)\tLoss 0.2050 (0.1633)\tPrec 89.844% (94.450%)\n",
      "Epoch: [51][300/391]\tTime 0.021 (0.022)\tData 0.002 (0.002)\tLoss 0.1463 (0.1652)\tPrec 94.531% (94.451%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.191 (0.191)\tLoss 0.3538 (0.3538)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.760% \n",
      "best acc: 88.300000\n",
      "Epoch: [52][0/391]\tTime 0.313 (0.313)\tData 0.293 (0.293)\tLoss 0.1312 (0.1312)\tPrec 96.875% (96.875%)\n",
      "Epoch: [52][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.2019 (0.1648)\tPrec 91.406% (94.384%)\n",
      "Epoch: [52][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1267 (0.1636)\tPrec 94.531% (94.426%)\n",
      "Epoch: [52][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.2066 (0.1639)\tPrec 93.750% (94.498%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.291 (0.291)\tLoss 0.3539 (0.3539)\tPrec 86.719% (86.719%)\n",
      " * Prec 87.430% \n",
      "best acc: 88.300000\n",
      "Epoch: [53][0/391]\tTime 0.349 (0.349)\tData 0.327 (0.327)\tLoss 0.1490 (0.1490)\tPrec 94.531% (94.531%)\n",
      "Epoch: [53][100/391]\tTime 0.021 (0.024)\tData 0.002 (0.005)\tLoss 0.2196 (0.1460)\tPrec 92.188% (94.833%)\n",
      "Epoch: [53][200/391]\tTime 0.021 (0.023)\tData 0.002 (0.003)\tLoss 0.1839 (0.1567)\tPrec 93.750% (94.632%)\n",
      "Epoch: [53][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1494 (0.1599)\tPrec 95.312% (94.575%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.2710 (0.2710)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.620% \n",
      "best acc: 88.300000\n",
      "Epoch: [54][0/391]\tTime 0.303 (0.303)\tData 0.281 (0.281)\tLoss 0.1307 (0.1307)\tPrec 95.312% (95.312%)\n",
      "Epoch: [54][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1316 (0.1495)\tPrec 96.094% (94.918%)\n",
      "Epoch: [54][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2746 (0.1535)\tPrec 92.969% (94.788%)\n",
      "Epoch: [54][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1777 (0.1594)\tPrec 95.312% (94.518%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.3251 (0.3251)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.430% \n",
      "best acc: 88.300000\n",
      "Epoch: [55][0/391]\tTime 0.312 (0.312)\tData 0.290 (0.290)\tLoss 0.2038 (0.2038)\tPrec 94.531% (94.531%)\n",
      "Epoch: [55][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1505 (0.1465)\tPrec 95.312% (95.150%)\n",
      "Epoch: [55][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1566 (0.1552)\tPrec 94.531% (94.807%)\n",
      "Epoch: [55][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.1442 (0.1558)\tPrec 93.750% (94.760%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.2244 (0.2244)\tPrec 95.312% (95.312%)\n",
      " * Prec 87.790% \n",
      "best acc: 88.300000\n",
      "Epoch: [56][0/391]\tTime 0.331 (0.331)\tData 0.308 (0.308)\tLoss 0.0684 (0.0684)\tPrec 96.875% (96.875%)\n",
      "Epoch: [56][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1275 (0.1532)\tPrec 96.094% (94.771%)\n",
      "Epoch: [56][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.2502 (0.1539)\tPrec 92.188% (94.862%)\n",
      "Epoch: [56][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.2150 (0.1574)\tPrec 92.188% (94.703%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.1670 (0.1670)\tPrec 95.312% (95.312%)\n",
      " * Prec 87.570% \n",
      "best acc: 88.300000\n",
      "Epoch: [57][0/391]\tTime 0.388 (0.388)\tData 0.321 (0.321)\tLoss 0.1889 (0.1889)\tPrec 92.188% (92.188%)\n",
      "Epoch: [57][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.004)\tLoss 0.0885 (0.1401)\tPrec 96.875% (95.282%)\n",
      "Epoch: [57][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2494 (0.1481)\tPrec 93.750% (94.951%)\n",
      "Epoch: [57][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1000 (0.1519)\tPrec 96.875% (94.806%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 0.4388 (0.4388)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.840% \n",
      "best acc: 88.300000\n",
      "Epoch: [58][0/391]\tTime 0.306 (0.306)\tData 0.284 (0.284)\tLoss 0.1431 (0.1431)\tPrec 92.969% (92.969%)\n",
      "Epoch: [58][100/391]\tTime 0.018 (0.023)\tData 0.001 (0.004)\tLoss 0.1788 (0.1456)\tPrec 92.969% (95.088%)\n",
      "Epoch: [58][200/391]\tTime 0.018 (0.022)\tData 0.001 (0.003)\tLoss 0.1224 (0.1533)\tPrec 96.875% (94.904%)\n",
      "Epoch: [58][300/391]\tTime 0.018 (0.021)\tData 0.001 (0.002)\tLoss 0.1711 (0.1567)\tPrec 92.969% (94.760%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.3232 (0.3232)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.050% \n",
      "best acc: 88.300000\n",
      "Epoch: [59][0/391]\tTime 0.309 (0.309)\tData 0.286 (0.286)\tLoss 0.1079 (0.1079)\tPrec 95.312% (95.312%)\n",
      "Epoch: [59][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1660 (0.1289)\tPrec 94.531% (95.614%)\n",
      "Epoch: [59][200/391]\tTime 0.020 (0.021)\tData 0.002 (0.003)\tLoss 0.1406 (0.1408)\tPrec 95.312% (95.227%)\n",
      "Epoch: [59][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1608 (0.1476)\tPrec 94.531% (94.962%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.193 (0.193)\tLoss 0.3209 (0.3209)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.050% \n",
      "best acc: 88.300000\n",
      "Epoch: [60][0/391]\tTime 0.319 (0.319)\tData 0.298 (0.298)\tLoss 0.0914 (0.0914)\tPrec 96.875% (96.875%)\n",
      "Epoch: [60][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1627 (0.1377)\tPrec 94.531% (95.243%)\n",
      "Epoch: [60][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1598 (0.1443)\tPrec 96.094% (95.079%)\n",
      "Epoch: [60][300/391]\tTime 0.020 (0.021)\tData 0.002 (0.002)\tLoss 0.0974 (0.1498)\tPrec 96.094% (94.908%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.3721 (0.3721)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.870% \n",
      "best acc: 88.300000\n",
      "Epoch: [61][0/391]\tTime 0.334 (0.334)\tData 0.312 (0.312)\tLoss 0.1163 (0.1163)\tPrec 97.656% (97.656%)\n",
      "Epoch: [61][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1530 (0.1458)\tPrec 94.531% (95.104%)\n",
      "Epoch: [61][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.1127 (0.1499)\tPrec 96.094% (94.893%)\n",
      "Epoch: [61][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.2287 (0.1489)\tPrec 93.750% (94.921%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.2620 (0.2620)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.250% \n",
      "best acc: 88.300000\n",
      "Epoch: [62][0/391]\tTime 0.318 (0.318)\tData 0.298 (0.298)\tLoss 0.1942 (0.1942)\tPrec 93.750% (93.750%)\n",
      "Epoch: [62][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1017 (0.1411)\tPrec 95.312% (95.436%)\n",
      "Epoch: [62][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.1997 (0.1427)\tPrec 94.531% (95.274%)\n",
      "Epoch: [62][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1824 (0.1428)\tPrec 95.312% (95.271%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.3081 (0.3081)\tPrec 86.719% (86.719%)\n",
      " * Prec 88.650% \n",
      "best acc: 88.650000\n",
      "Epoch: [63][0/391]\tTime 0.383 (0.383)\tData 0.361 (0.361)\tLoss 0.1677 (0.1677)\tPrec 94.531% (94.531%)\n",
      "Epoch: [63][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.0944 (0.1430)\tPrec 96.094% (95.243%)\n",
      "Epoch: [63][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1030 (0.1459)\tPrec 97.656% (95.075%)\n",
      "Epoch: [63][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1383 (0.1472)\tPrec 93.750% (95.014%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.3583 (0.3583)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.980% \n",
      "best acc: 88.650000\n",
      "Epoch: [64][0/391]\tTime 0.314 (0.314)\tData 0.293 (0.293)\tLoss 0.1099 (0.1099)\tPrec 96.875% (96.875%)\n",
      "Epoch: [64][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.004)\tLoss 0.1608 (0.1528)\tPrec 95.312% (94.988%)\n",
      "Epoch: [64][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1919 (0.1451)\tPrec 94.531% (95.141%)\n",
      "Epoch: [64][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1700 (0.1460)\tPrec 93.750% (95.019%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.3486 (0.3486)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.910% \n",
      "best acc: 88.650000\n",
      "Epoch: [65][0/391]\tTime 0.306 (0.306)\tData 0.285 (0.285)\tLoss 0.1158 (0.1158)\tPrec 94.531% (94.531%)\n",
      "Epoch: [65][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1194 (0.1243)\tPrec 95.312% (95.808%)\n",
      "Epoch: [65][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.2213 (0.1367)\tPrec 93.750% (95.429%)\n",
      "Epoch: [65][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.2503 (0.1457)\tPrec 91.406% (95.170%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.3339 (0.3339)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.710% \n",
      "best acc: 88.650000\n",
      "Epoch: [66][0/391]\tTime 0.360 (0.360)\tData 0.334 (0.334)\tLoss 0.2296 (0.2296)\tPrec 92.969% (92.969%)\n",
      "Epoch: [66][100/391]\tTime 0.021 (0.024)\tData 0.001 (0.005)\tLoss 0.1225 (0.1214)\tPrec 95.312% (96.047%)\n",
      "Epoch: [66][200/391]\tTime 0.021 (0.023)\tData 0.001 (0.003)\tLoss 0.1528 (0.1321)\tPrec 93.750% (95.608%)\n",
      "Epoch: [66][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.002)\tLoss 0.0885 (0.1364)\tPrec 97.656% (95.398%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.3211 (0.3211)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.320% \n",
      "best acc: 88.650000\n",
      "Epoch: [67][0/391]\tTime 0.339 (0.339)\tData 0.316 (0.316)\tLoss 0.1711 (0.1711)\tPrec 94.531% (94.531%)\n",
      "Epoch: [67][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1410 (0.1436)\tPrec 94.531% (95.011%)\n",
      "Epoch: [67][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2026 (0.1473)\tPrec 89.844% (94.908%)\n",
      "Epoch: [67][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1710 (0.1461)\tPrec 94.531% (95.037%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.3136 (0.3136)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.660% \n",
      "best acc: 88.660000\n",
      "Epoch: [68][0/391]\tTime 0.483 (0.483)\tData 0.457 (0.457)\tLoss 0.0636 (0.0636)\tPrec 97.656% (97.656%)\n",
      "Epoch: [68][100/391]\tTime 0.020 (0.025)\tData 0.001 (0.006)\tLoss 0.0905 (0.1311)\tPrec 97.656% (95.591%)\n",
      "Epoch: [68][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.004)\tLoss 0.0869 (0.1381)\tPrec 96.094% (95.309%)\n",
      "Epoch: [68][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1355 (0.1403)\tPrec 95.312% (95.198%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.2870 (0.2870)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.640% \n",
      "best acc: 88.660000\n",
      "Epoch: [69][0/391]\tTime 0.424 (0.424)\tData 0.403 (0.403)\tLoss 0.1009 (0.1009)\tPrec 96.094% (96.094%)\n",
      "Epoch: [69][100/391]\tTime 0.021 (0.025)\tData 0.001 (0.005)\tLoss 0.1612 (0.1315)\tPrec 93.750% (95.614%)\n",
      "Epoch: [69][200/391]\tTime 0.021 (0.023)\tData 0.001 (0.003)\tLoss 0.1229 (0.1293)\tPrec 96.875% (95.756%)\n",
      "Epoch: [69][300/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.2065 (0.1361)\tPrec 95.312% (95.453%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.2643 (0.2643)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.910% \n",
      "best acc: 88.660000\n",
      "Epoch: [70][0/391]\tTime 0.342 (0.342)\tData 0.319 (0.319)\tLoss 0.1068 (0.1068)\tPrec 96.875% (96.875%)\n",
      "Epoch: [70][100/391]\tTime 0.021 (0.024)\tData 0.001 (0.005)\tLoss 0.1444 (0.1277)\tPrec 96.094% (95.521%)\n",
      "Epoch: [70][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1596 (0.1347)\tPrec 92.969% (95.379%)\n",
      "Epoch: [70][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1201 (0.1366)\tPrec 94.531% (95.331%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.3576 (0.3576)\tPrec 86.719% (86.719%)\n",
      " * Prec 88.460% \n",
      "best acc: 88.660000\n",
      "Epoch: [71][0/391]\tTime 0.319 (0.319)\tData 0.298 (0.298)\tLoss 0.0852 (0.0852)\tPrec 98.438% (98.438%)\n",
      "Epoch: [71][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1804 (0.1321)\tPrec 95.312% (95.374%)\n",
      "Epoch: [71][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1293 (0.1393)\tPrec 96.094% (95.188%)\n",
      "Epoch: [71][300/391]\tTime 0.020 (0.021)\tData 0.002 (0.002)\tLoss 0.1269 (0.1387)\tPrec 95.312% (95.263%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.2952 (0.2952)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.210% \n",
      "best acc: 89.210000\n",
      "Epoch: [72][0/391]\tTime 0.352 (0.352)\tData 0.330 (0.330)\tLoss 0.0684 (0.0684)\tPrec 99.219% (99.219%)\n",
      "Epoch: [72][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.005)\tLoss 0.1225 (0.1302)\tPrec 96.094% (95.583%)\n",
      "Epoch: [72][200/391]\tTime 0.020 (0.022)\tData 0.002 (0.003)\tLoss 0.1613 (0.1310)\tPrec 95.312% (95.553%)\n",
      "Epoch: [72][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.0961 (0.1320)\tPrec 96.094% (95.551%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.2762 (0.2762)\tPrec 91.406% (91.406%)\n",
      " * Prec 84.460% \n",
      "best acc: 89.210000\n",
      "Epoch: [73][0/391]\tTime 0.334 (0.334)\tData 0.313 (0.313)\tLoss 0.1118 (0.1118)\tPrec 96.875% (96.875%)\n",
      "Epoch: [73][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1716 (0.1279)\tPrec 94.531% (95.692%)\n",
      "Epoch: [73][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1178 (0.1326)\tPrec 96.094% (95.550%)\n",
      "Epoch: [73][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1155 (0.1332)\tPrec 96.094% (95.551%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.2680 (0.2680)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.220% \n",
      "best acc: 89.220000\n",
      "Epoch: [74][0/391]\tTime 0.377 (0.377)\tData 0.356 (0.356)\tLoss 0.1039 (0.1039)\tPrec 96.875% (96.875%)\n",
      "Epoch: [74][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.1150 (0.1184)\tPrec 97.656% (96.086%)\n",
      "Epoch: [74][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1013 (0.1259)\tPrec 95.312% (95.779%)\n",
      "Epoch: [74][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.0652 (0.1340)\tPrec 99.219% (95.453%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.3084 (0.3084)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.430% \n",
      "best acc: 89.220000\n",
      "Epoch: [75][0/391]\tTime 0.315 (0.315)\tData 0.293 (0.293)\tLoss 0.0886 (0.0886)\tPrec 98.438% (98.438%)\n",
      "Epoch: [75][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1516 (0.1166)\tPrec 95.312% (95.970%)\n",
      "Epoch: [75][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1279 (0.1182)\tPrec 95.312% (96.024%)\n",
      "Epoch: [75][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0816 (0.1246)\tPrec 97.656% (95.782%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.286 (0.286)\tLoss 0.1827 (0.1827)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.580% \n",
      "best acc: 89.220000\n",
      "Epoch: [76][0/391]\tTime 0.342 (0.342)\tData 0.321 (0.321)\tLoss 0.0760 (0.0760)\tPrec 96.094% (96.094%)\n",
      "Epoch: [76][100/391]\tTime 0.020 (0.026)\tData 0.001 (0.005)\tLoss 0.1000 (0.1228)\tPrec 96.875% (95.777%)\n",
      "Epoch: [76][200/391]\tTime 0.027 (0.023)\tData 0.011 (0.003)\tLoss 0.1356 (0.1269)\tPrec 95.312% (95.744%)\n",
      "Epoch: [76][300/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1296 (0.1301)\tPrec 93.750% (95.603%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.2764 (0.2764)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.360% \n",
      "best acc: 89.220000\n",
      "Epoch: [77][0/391]\tTime 0.323 (0.323)\tData 0.297 (0.297)\tLoss 0.0655 (0.0655)\tPrec 98.438% (98.438%)\n",
      "Epoch: [77][100/391]\tTime 0.021 (0.023)\tData 0.001 (0.004)\tLoss 0.0816 (0.1248)\tPrec 97.656% (95.792%)\n",
      "Epoch: [77][200/391]\tTime 0.021 (0.021)\tData 0.001 (0.003)\tLoss 0.0972 (0.1288)\tPrec 98.438% (95.705%)\n",
      "Epoch: [77][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.002)\tLoss 0.0670 (0.1307)\tPrec 98.438% (95.647%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.2305 (0.2305)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.230% \n",
      "best acc: 89.220000\n",
      "Epoch: [78][0/391]\tTime 0.326 (0.326)\tData 0.305 (0.305)\tLoss 0.1305 (0.1305)\tPrec 94.531% (94.531%)\n",
      "Epoch: [78][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1012 (0.1231)\tPrec 96.094% (95.908%)\n",
      "Epoch: [78][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2100 (0.1252)\tPrec 94.531% (95.814%)\n",
      "Epoch: [78][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1146 (0.1279)\tPrec 95.312% (95.668%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.3550 (0.3550)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.500% \n",
      "best acc: 89.220000\n",
      "Epoch: [79][0/391]\tTime 0.340 (0.340)\tData 0.312 (0.312)\tLoss 0.1858 (0.1858)\tPrec 93.750% (93.750%)\n",
      "Epoch: [79][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1970 (0.1150)\tPrec 92.188% (96.078%)\n",
      "Epoch: [79][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1918 (0.1233)\tPrec 94.531% (95.794%)\n",
      "Epoch: [79][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1085 (0.1255)\tPrec 93.750% (95.746%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.3572 (0.3572)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.970% \n",
      "best acc: 89.220000\n",
      "Epoch: [80][0/391]\tTime 0.356 (0.356)\tData 0.335 (0.335)\tLoss 0.1290 (0.1290)\tPrec 96.094% (96.094%)\n",
      "Epoch: [80][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.005)\tLoss 0.1877 (0.1063)\tPrec 94.531% (96.419%)\n",
      "Epoch: [80][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.0609 (0.1142)\tPrec 98.438% (96.195%)\n",
      "Epoch: [80][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0576 (0.1196)\tPrec 98.438% (95.995%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 0.4044 (0.4044)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.580% \n",
      "best acc: 89.220000\n",
      "Epoch: [81][0/391]\tTime 0.339 (0.339)\tData 0.318 (0.318)\tLoss 0.1117 (0.1117)\tPrec 95.312% (95.312%)\n",
      "Epoch: [81][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.0574 (0.1045)\tPrec 98.438% (96.310%)\n",
      "Epoch: [81][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.1143 (0.1070)\tPrec 94.531% (96.276%)\n",
      "Epoch: [81][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1498 (0.1158)\tPrec 92.969% (95.998%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.2730 (0.2730)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.850% \n",
      "best acc: 89.220000\n",
      "Epoch: [82][0/391]\tTime 0.323 (0.323)\tData 0.300 (0.300)\tLoss 0.1529 (0.1529)\tPrec 94.531% (94.531%)\n",
      "Epoch: [82][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.0572 (0.1176)\tPrec 98.438% (96.148%)\n",
      "Epoch: [82][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1307 (0.1143)\tPrec 96.094% (96.199%)\n",
      "Epoch: [82][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1340 (0.1169)\tPrec 95.312% (96.081%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 0.3128 (0.3128)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.870% \n",
      "best acc: 89.220000\n",
      "Epoch: [83][0/391]\tTime 0.326 (0.326)\tData 0.303 (0.303)\tLoss 0.2423 (0.2423)\tPrec 92.969% (92.969%)\n",
      "Epoch: [83][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1461 (0.1091)\tPrec 96.094% (96.357%)\n",
      "Epoch: [83][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2586 (0.1181)\tPrec 92.188% (96.094%)\n",
      "Epoch: [83][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1185 (0.1194)\tPrec 96.875% (95.972%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 0.4659 (0.4659)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.210% \n",
      "best acc: 89.220000\n",
      "Epoch: [84][0/391]\tTime 0.324 (0.324)\tData 0.301 (0.301)\tLoss 0.0379 (0.0379)\tPrec 98.438% (98.438%)\n",
      "Epoch: [84][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1159 (0.1148)\tPrec 96.875% (96.241%)\n",
      "Epoch: [84][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.1077 (0.1123)\tPrec 97.656% (96.230%)\n",
      "Epoch: [84][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1650 (0.1165)\tPrec 94.531% (96.076%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.3336 (0.3336)\tPrec 89.062% (89.062%)\n",
      " * Prec 88.160% \n",
      "best acc: 89.220000\n",
      "Epoch: [85][0/391]\tTime 0.327 (0.327)\tData 0.304 (0.304)\tLoss 0.0513 (0.0513)\tPrec 98.438% (98.438%)\n",
      "Epoch: [85][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.0616 (0.1054)\tPrec 98.438% (96.349%)\n",
      "Epoch: [85][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1285 (0.1115)\tPrec 96.875% (96.292%)\n",
      "Epoch: [85][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1908 (0.1167)\tPrec 94.531% (96.102%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.2252 (0.2252)\tPrec 94.531% (94.531%)\n",
      " * Prec 87.620% \n",
      "best acc: 89.220000\n",
      "Epoch: [86][0/391]\tTime 0.345 (0.345)\tData 0.322 (0.322)\tLoss 0.1102 (0.1102)\tPrec 97.656% (97.656%)\n",
      "Epoch: [86][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.005)\tLoss 0.0871 (0.1075)\tPrec 96.094% (96.434%)\n",
      "Epoch: [86][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1490 (0.1131)\tPrec 94.531% (96.214%)\n",
      "Epoch: [86][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1868 (0.1179)\tPrec 92.188% (96.011%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.274 (0.274)\tLoss 0.2331 (0.2331)\tPrec 95.312% (95.312%)\n",
      " * Prec 88.490% \n",
      "best acc: 89.220000\n",
      "Epoch: [87][0/391]\tTime 0.397 (0.397)\tData 0.375 (0.375)\tLoss 0.0643 (0.0643)\tPrec 97.656% (97.656%)\n",
      "Epoch: [87][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.1212 (0.1007)\tPrec 97.656% (96.488%)\n",
      "Epoch: [87][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1635 (0.1071)\tPrec 94.531% (96.319%)\n",
      "Epoch: [87][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.1504 (0.1117)\tPrec 92.969% (96.177%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.185 (0.185)\tLoss 0.4988 (0.4988)\tPrec 86.719% (86.719%)\n",
      " * Prec 86.570% \n",
      "best acc: 89.220000\n",
      "Epoch: [88][0/391]\tTime 0.339 (0.339)\tData 0.315 (0.315)\tLoss 0.1276 (0.1276)\tPrec 96.875% (96.875%)\n",
      "Epoch: [88][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.0983 (0.1161)\tPrec 98.438% (96.047%)\n",
      "Epoch: [88][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.1337 (0.1170)\tPrec 94.531% (95.954%)\n",
      "Epoch: [88][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0929 (0.1204)\tPrec 98.438% (95.899%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.2768 (0.2768)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.610% \n",
      "best acc: 89.610000\n",
      "Epoch: [89][0/391]\tTime 0.372 (0.372)\tData 0.351 (0.351)\tLoss 0.0868 (0.0868)\tPrec 97.656% (97.656%)\n",
      "Epoch: [89][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.005)\tLoss 0.1461 (0.1078)\tPrec 95.312% (96.357%)\n",
      "Epoch: [89][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1052 (0.1126)\tPrec 97.656% (96.191%)\n",
      "Epoch: [89][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1074 (0.1122)\tPrec 96.094% (96.203%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.4052 (0.4052)\tPrec 87.500% (87.500%)\n",
      " * Prec 88.030% \n",
      "best acc: 89.610000\n",
      "Epoch: [90][0/391]\tTime 0.311 (0.311)\tData 0.290 (0.290)\tLoss 0.1331 (0.1331)\tPrec 94.531% (94.531%)\n",
      "Epoch: [90][100/391]\tTime 0.021 (0.023)\tData 0.001 (0.004)\tLoss 0.1492 (0.0978)\tPrec 97.656% (96.658%)\n",
      "Epoch: [90][200/391]\tTime 0.021 (0.021)\tData 0.001 (0.003)\tLoss 0.1018 (0.1121)\tPrec 95.312% (96.249%)\n",
      "Epoch: [90][300/391]\tTime 0.022 (0.021)\tData 0.001 (0.002)\tLoss 0.1621 (0.1146)\tPrec 95.312% (96.143%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.181 (0.181)\tLoss 0.3883 (0.3883)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.940% \n",
      "best acc: 89.610000\n",
      "Epoch: [91][0/391]\tTime 0.401 (0.401)\tData 0.378 (0.378)\tLoss 0.1513 (0.1513)\tPrec 96.094% (96.094%)\n",
      "Epoch: [91][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.1172 (0.1000)\tPrec 96.875% (96.720%)\n",
      "Epoch: [91][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1996 (0.1101)\tPrec 94.531% (96.288%)\n",
      "Epoch: [91][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1256 (0.1165)\tPrec 96.094% (96.151%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.2326 (0.2326)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.500% \n",
      "best acc: 89.610000\n",
      "Epoch: [92][0/391]\tTime 0.320 (0.320)\tData 0.298 (0.298)\tLoss 0.1376 (0.1376)\tPrec 94.531% (94.531%)\n",
      "Epoch: [92][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1236 (0.1138)\tPrec 96.094% (96.078%)\n",
      "Epoch: [92][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2634 (0.1149)\tPrec 92.188% (96.043%)\n",
      "Epoch: [92][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0564 (0.1168)\tPrec 99.219% (96.013%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.2617 (0.2617)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.480% \n",
      "best acc: 89.610000\n",
      "Epoch: [93][0/391]\tTime 0.328 (0.328)\tData 0.305 (0.305)\tLoss 0.1535 (0.1535)\tPrec 94.531% (94.531%)\n",
      "Epoch: [93][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.0505 (0.1099)\tPrec 98.438% (96.202%)\n",
      "Epoch: [93][200/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.0655 (0.1104)\tPrec 98.438% (96.203%)\n",
      "Epoch: [93][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1661 (0.1135)\tPrec 94.531% (96.120%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.1903 (0.1903)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.540% \n",
      "best acc: 89.610000\n",
      "Epoch: [94][0/391]\tTime 0.336 (0.336)\tData 0.313 (0.313)\tLoss 0.1518 (0.1518)\tPrec 94.531% (94.531%)\n",
      "Epoch: [94][100/391]\tTime 0.022 (0.023)\tData 0.002 (0.005)\tLoss 0.0852 (0.1035)\tPrec 97.656% (96.457%)\n",
      "Epoch: [94][200/391]\tTime 0.022 (0.022)\tData 0.001 (0.003)\tLoss 0.0600 (0.1125)\tPrec 97.656% (96.230%)\n",
      "Epoch: [94][300/391]\tTime 0.021 (0.021)\tData 0.001 (0.003)\tLoss 0.1504 (0.1151)\tPrec 94.531% (96.104%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.2661 (0.2661)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.530% \n",
      "best acc: 89.610000\n",
      "Epoch: [95][0/391]\tTime 0.425 (0.425)\tData 0.398 (0.398)\tLoss 0.1624 (0.1624)\tPrec 94.531% (94.531%)\n",
      "Epoch: [95][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.1447 (0.1016)\tPrec 95.312% (96.581%)\n",
      "Epoch: [95][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1441 (0.1108)\tPrec 93.750% (96.249%)\n",
      "Epoch: [95][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.0711 (0.1137)\tPrec 96.875% (96.161%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.3427 (0.3427)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.550% \n",
      "best acc: 89.610000\n",
      "Epoch: [96][0/391]\tTime 0.327 (0.327)\tData 0.305 (0.305)\tLoss 0.0481 (0.0481)\tPrec 97.656% (97.656%)\n",
      "Epoch: [96][100/391]\tTime 0.021 (0.024)\tData 0.002 (0.005)\tLoss 0.0499 (0.1064)\tPrec 98.438% (96.434%)\n",
      "Epoch: [96][200/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.1273 (0.1148)\tPrec 96.875% (96.121%)\n",
      "Epoch: [96][300/391]\tTime 0.020 (0.022)\tData 0.002 (0.003)\tLoss 0.1163 (0.1164)\tPrec 96.094% (96.112%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.3221 (0.3221)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.610% \n",
      "best acc: 89.610000\n",
      "Epoch: [97][0/391]\tTime 0.333 (0.333)\tData 0.311 (0.311)\tLoss 0.0563 (0.0563)\tPrec 97.656% (97.656%)\n",
      "Epoch: [97][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1572 (0.1067)\tPrec 94.531% (96.450%)\n",
      "Epoch: [97][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1645 (0.1090)\tPrec 93.750% (96.276%)\n",
      "Epoch: [97][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1463 (0.1126)\tPrec 94.531% (96.200%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.188 (0.188)\tLoss 0.3119 (0.3119)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.970% \n",
      "best acc: 89.610000\n",
      "Epoch: [98][0/391]\tTime 0.373 (0.373)\tData 0.296 (0.296)\tLoss 0.1141 (0.1141)\tPrec 96.094% (96.094%)\n",
      "Epoch: [98][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1811 (0.0946)\tPrec 95.312% (96.890%)\n",
      "Epoch: [98][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1499 (0.1119)\tPrec 93.750% (96.226%)\n",
      "Epoch: [98][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1159 (0.1155)\tPrec 94.531% (96.060%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.2666 (0.2666)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.160% \n",
      "best acc: 89.610000\n",
      "Epoch: [99][0/391]\tTime 0.378 (0.378)\tData 0.355 (0.355)\tLoss 0.0762 (0.0762)\tPrec 98.438% (98.438%)\n",
      "Epoch: [99][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.005)\tLoss 0.1092 (0.1074)\tPrec 95.312% (96.519%)\n",
      "Epoch: [99][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.1102 (0.1089)\tPrec 96.875% (96.362%)\n",
      "Epoch: [99][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0827 (0.1150)\tPrec 97.656% (96.130%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.2617 (0.2617)\tPrec 89.062% (89.062%)\n",
      " * Prec 88.400% \n",
      "best acc: 89.610000\n",
      "Epoch: [100][0/391]\tTime 0.330 (0.330)\tData 0.306 (0.306)\tLoss 0.0599 (0.0599)\tPrec 96.875% (96.875%)\n",
      "Epoch: [100][100/391]\tTime 0.020 (0.024)\tData 0.002 (0.005)\tLoss 0.1081 (0.1014)\tPrec 96.875% (96.744%)\n",
      "Epoch: [100][200/391]\tTime 0.020 (0.022)\tData 0.002 (0.003)\tLoss 0.0911 (0.1011)\tPrec 96.875% (96.661%)\n",
      "Epoch: [100][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.003)\tLoss 0.1149 (0.1075)\tPrec 95.312% (96.377%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.272 (0.272)\tLoss 0.3835 (0.3835)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.090% \n",
      "best acc: 89.610000\n",
      "Epoch: [101][0/391]\tTime 0.338 (0.338)\tData 0.316 (0.316)\tLoss 0.0658 (0.0658)\tPrec 97.656% (97.656%)\n",
      "Epoch: [101][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.0607 (0.1047)\tPrec 96.875% (96.496%)\n",
      "Epoch: [101][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.0756 (0.1104)\tPrec 97.656% (96.241%)\n",
      "Epoch: [101][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.0709 (0.1097)\tPrec 95.312% (96.281%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 0.4179 (0.4179)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.550% \n",
      "best acc: 89.610000\n",
      "Epoch: [102][0/391]\tTime 0.393 (0.393)\tData 0.371 (0.371)\tLoss 0.1934 (0.1934)\tPrec 95.312% (95.312%)\n",
      "Epoch: [102][100/391]\tTime 0.020 (0.024)\tData 0.002 (0.005)\tLoss 0.0840 (0.1109)\tPrec 97.656% (96.341%)\n",
      "Epoch: [102][200/391]\tTime 0.021 (0.022)\tData 0.002 (0.004)\tLoss 0.1031 (0.1087)\tPrec 96.094% (96.432%)\n",
      "Epoch: [102][300/391]\tTime 0.021 (0.022)\tData 0.002 (0.003)\tLoss 0.0917 (0.1095)\tPrec 97.656% (96.410%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.3667 (0.3667)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.960% \n",
      "best acc: 89.610000\n",
      "Epoch: [103][0/391]\tTime 0.299 (0.299)\tData 0.278 (0.278)\tLoss 0.1445 (0.1445)\tPrec 95.312% (95.312%)\n",
      "Epoch: [103][100/391]\tTime 0.020 (0.023)\tData 0.001 (0.004)\tLoss 0.1964 (0.1093)\tPrec 92.969% (96.326%)\n",
      "Epoch: [103][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2024 (0.1116)\tPrec 93.750% (96.269%)\n",
      "Epoch: [103][300/391]\tTime 0.022 (0.021)\tData 0.001 (0.002)\tLoss 0.1236 (0.1119)\tPrec 96.094% (96.226%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.2578 (0.2578)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.550% \n",
      "best acc: 89.610000\n",
      "Epoch: [104][0/391]\tTime 0.336 (0.336)\tData 0.315 (0.315)\tLoss 0.0964 (0.0964)\tPrec 95.312% (95.312%)\n",
      "Epoch: [104][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.1125 (0.1106)\tPrec 96.875% (96.218%)\n",
      "Epoch: [104][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.0720 (0.1114)\tPrec 97.656% (96.164%)\n",
      "Epoch: [104][300/391]\tTime 0.020 (0.021)\tData 0.002 (0.003)\tLoss 0.0868 (0.1137)\tPrec 96.875% (96.117%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.3468 (0.3468)\tPrec 90.625% (90.625%)\n",
      " * Prec 85.310% \n",
      "best acc: 89.610000\n",
      "Epoch: [105][0/391]\tTime 0.377 (0.377)\tData 0.355 (0.355)\tLoss 0.1497 (0.1497)\tPrec 93.750% (93.750%)\n",
      "Epoch: [105][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.0810 (0.1040)\tPrec 97.656% (96.225%)\n",
      "Epoch: [105][200/391]\tTime 0.019 (0.022)\tData 0.001 (0.003)\tLoss 0.2182 (0.1020)\tPrec 92.188% (96.374%)\n",
      "Epoch: [105][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1195 (0.1048)\tPrec 94.531% (96.356%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.2860 (0.2860)\tPrec 88.281% (88.281%)\n",
      " * Prec 89.790% \n",
      "best acc: 89.790000\n",
      "Epoch: [106][0/391]\tTime 0.361 (0.361)\tData 0.339 (0.339)\tLoss 0.0997 (0.0997)\tPrec 97.656% (97.656%)\n",
      "Epoch: [106][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.1389 (0.1048)\tPrec 94.531% (96.403%)\n",
      "Epoch: [106][200/391]\tTime 0.020 (0.022)\tData 0.001 (0.003)\tLoss 0.2191 (0.1056)\tPrec 94.531% (96.459%)\n",
      "Epoch: [106][300/391]\tTime 0.020 (0.021)\tData 0.001 (0.002)\tLoss 0.1999 (0.1117)\tPrec 90.625% (96.247%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.4581 (0.4581)\tPrec 86.719% (86.719%)\n",
      " * Prec 87.790% \n",
      "best acc: 89.790000\n",
      "Epoch: [107][0/391]\tTime 0.309 (0.309)\tData 0.285 (0.285)\tLoss 0.1092 (0.1092)\tPrec 94.531% (94.531%)\n",
      "Epoch: [107][100/391]\tTime 0.020 (0.023)\tData 0.002 (0.004)\tLoss 0.0972 (0.1077)\tPrec 96.094% (96.334%)\n",
      "Epoch: [107][200/391]\tTime 0.020 (0.022)\tData 0.002 (0.003)\tLoss 0.0944 (0.1054)\tPrec 98.438% (96.393%)\n",
      "Epoch: [107][300/391]\tTime 0.020 (0.021)\tData 0.002 (0.003)\tLoss 0.1167 (0.1093)\tPrec 96.875% (96.325%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 0.2870 (0.2870)\tPrec 89.062% (89.062%)\n",
      " * Prec 88.200% \n",
      "best acc: 89.790000\n",
      "Epoch: [108][0/391]\tTime 0.353 (0.353)\tData 0.331 (0.331)\tLoss 0.0381 (0.0381)\tPrec 99.219% (99.219%)\n",
      "Epoch: [108][100/391]\tTime 0.020 (0.024)\tData 0.001 (0.005)\tLoss 0.0293 (0.1000)\tPrec 100.000% (96.821%)\n",
      "Epoch: [108][200/391]\tTime 0.021 (0.022)\tData 0.001 (0.003)\tLoss 0.1870 (0.1027)\tPrec 92.969% (96.681%)\n",
      "Epoch: [108][300/391]\tTime 0.020 (0.025)\tData 0.002 (0.003)\tLoss 0.1730 (0.1103)\tPrec 92.188% (96.333%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.2934 (0.2934)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.260% \n",
      "best acc: 89.790000\n",
      "Epoch: [109][0/391]\tTime 0.344 (0.344)\tData 0.318 (0.318)\tLoss 0.0796 (0.0796)\tPrec 98.438% (98.438%)\n",
      "Epoch: [109][100/391]\tTime 0.044 (0.046)\tData 0.001 (0.004)\tLoss 0.0547 (0.1048)\tPrec 98.438% (96.287%)\n",
      "Epoch: [109][200/391]\tTime 0.043 (0.045)\tData 0.001 (0.003)\tLoss 0.1254 (0.1006)\tPrec 96.094% (96.494%)\n",
      "Epoch: [109][300/391]\tTime 0.043 (0.044)\tData 0.001 (0.002)\tLoss 0.1123 (0.1059)\tPrec 97.656% (96.353%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 0.3733 (0.3733)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.750% \n",
      "best acc: 89.790000\n",
      "Epoch: [110][0/391]\tTime 0.492 (0.492)\tData 0.466 (0.466)\tLoss 0.0380 (0.0380)\tPrec 99.219% (99.219%)\n",
      "Epoch: [110][100/391]\tTime 0.043 (0.048)\tData 0.002 (0.006)\tLoss 0.0436 (0.0865)\tPrec 97.656% (97.099%)\n",
      "Epoch: [110][200/391]\tTime 0.043 (0.045)\tData 0.002 (0.004)\tLoss 0.1825 (0.0985)\tPrec 92.969% (96.646%)\n",
      "Epoch: [110][300/391]\tTime 0.043 (0.045)\tData 0.002 (0.003)\tLoss 0.1089 (0.1037)\tPrec 95.312% (96.480%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.238 (0.238)\tLoss 0.2704 (0.2704)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.160% \n",
      "best acc: 89.790000\n",
      "Epoch: [111][0/391]\tTime 0.558 (0.558)\tData 0.529 (0.529)\tLoss 0.0382 (0.0382)\tPrec 99.219% (99.219%)\n",
      "Epoch: [111][100/391]\tTime 0.044 (0.048)\tData 0.001 (0.006)\tLoss 0.0661 (0.1076)\tPrec 96.875% (96.334%)\n",
      "Epoch: [111][200/391]\tTime 0.046 (0.046)\tData 0.001 (0.004)\tLoss 0.1226 (0.1073)\tPrec 96.875% (96.311%)\n",
      "Epoch: [111][300/391]\tTime 0.040 (0.045)\tData 0.001 (0.003)\tLoss 0.1271 (0.1080)\tPrec 95.312% (96.307%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.424 (0.424)\tLoss 0.3419 (0.3419)\tPrec 87.500% (87.500%)\n",
      " * Prec 87.920% \n",
      "best acc: 89.790000\n",
      "Epoch: [112][0/391]\tTime 0.332 (0.332)\tData 0.308 (0.308)\tLoss 0.1359 (0.1359)\tPrec 93.750% (93.750%)\n",
      "Epoch: [112][100/391]\tTime 0.044 (0.045)\tData 0.001 (0.004)\tLoss 0.0372 (0.0961)\tPrec 99.219% (96.612%)\n",
      "Epoch: [112][200/391]\tTime 0.044 (0.044)\tData 0.001 (0.003)\tLoss 0.1147 (0.1012)\tPrec 96.094% (96.529%)\n",
      "Epoch: [112][300/391]\tTime 0.042 (0.044)\tData 0.001 (0.002)\tLoss 0.1187 (0.1033)\tPrec 96.094% (96.480%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.3657 (0.3657)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.010% \n",
      "best acc: 89.790000\n",
      "Epoch: [113][0/391]\tTime 0.397 (0.397)\tData 0.375 (0.375)\tLoss 0.1344 (0.1344)\tPrec 96.094% (96.094%)\n",
      "Epoch: [113][100/391]\tTime 0.043 (0.040)\tData 0.001 (0.005)\tLoss 0.1052 (0.0985)\tPrec 96.094% (96.597%)\n",
      "Epoch: [113][200/391]\tTime 0.044 (0.042)\tData 0.001 (0.003)\tLoss 0.1254 (0.1013)\tPrec 98.438% (96.525%)\n",
      "Epoch: [113][300/391]\tTime 0.043 (0.042)\tData 0.002 (0.003)\tLoss 0.1576 (0.1070)\tPrec 94.531% (96.296%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.301 (0.301)\tLoss 0.3133 (0.3133)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.650% \n",
      "best acc: 89.790000\n",
      "Epoch: [114][0/391]\tTime 0.444 (0.444)\tData 0.417 (0.417)\tLoss 0.1696 (0.1696)\tPrec 93.750% (93.750%)\n",
      "Epoch: [114][100/391]\tTime 0.043 (0.039)\tData 0.001 (0.006)\tLoss 0.1200 (0.0970)\tPrec 96.875% (96.627%)\n",
      "Epoch: [114][200/391]\tTime 0.043 (0.041)\tData 0.001 (0.004)\tLoss 0.1085 (0.0998)\tPrec 96.875% (96.646%)\n",
      "Epoch: [114][300/391]\tTime 0.046 (0.042)\tData 0.001 (0.003)\tLoss 0.1549 (0.1011)\tPrec 95.312% (96.571%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.306 (0.306)\tLoss 0.3212 (0.3212)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.880% \n",
      "best acc: 89.790000\n",
      "Epoch: [115][0/391]\tTime 0.399 (0.399)\tData 0.369 (0.369)\tLoss 0.0384 (0.0384)\tPrec 98.438% (98.438%)\n",
      "Epoch: [115][100/391]\tTime 0.044 (0.041)\tData 0.001 (0.007)\tLoss 0.0567 (0.0911)\tPrec 97.656% (96.867%)\n",
      "Epoch: [115][200/391]\tTime 0.044 (0.042)\tData 0.001 (0.004)\tLoss 0.0178 (0.0972)\tPrec 100.000% (96.638%)\n",
      "Epoch: [115][300/391]\tTime 0.044 (0.043)\tData 0.001 (0.003)\tLoss 0.1664 (0.1021)\tPrec 94.531% (96.475%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.300 (0.300)\tLoss 0.2697 (0.2697)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.160% \n",
      "best acc: 89.790000\n",
      "Epoch: [116][0/391]\tTime 0.355 (0.355)\tData 0.327 (0.327)\tLoss 0.1411 (0.1411)\tPrec 95.312% (95.312%)\n",
      "Epoch: [116][100/391]\tTime 0.044 (0.045)\tData 0.001 (0.008)\tLoss 0.0877 (0.0978)\tPrec 97.656% (96.566%)\n",
      "Epoch: [116][200/391]\tTime 0.043 (0.044)\tData 0.001 (0.004)\tLoss 0.1571 (0.0937)\tPrec 92.969% (96.712%)\n",
      "Epoch: [116][300/391]\tTime 0.043 (0.044)\tData 0.001 (0.003)\tLoss 0.0977 (0.0992)\tPrec 96.875% (96.564%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.322 (0.322)\tLoss 0.5547 (0.5547)\tPrec 84.375% (84.375%)\n",
      " * Prec 85.470% \n",
      "best acc: 89.790000\n",
      "Epoch: [117][0/391]\tTime 0.480 (0.480)\tData 0.453 (0.453)\tLoss 0.0330 (0.0330)\tPrec 100.000% (100.000%)\n",
      "Epoch: [117][100/391]\tTime 0.041 (0.042)\tData 0.001 (0.009)\tLoss 0.0987 (0.0986)\tPrec 96.875% (96.658%)\n",
      "Epoch: [117][200/391]\tTime 0.043 (0.043)\tData 0.001 (0.005)\tLoss 0.2590 (0.1064)\tPrec 89.844% (96.381%)\n",
      "Epoch: [117][300/391]\tTime 0.043 (0.043)\tData 0.001 (0.004)\tLoss 0.1254 (0.1059)\tPrec 96.094% (96.405%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.321 (0.321)\tLoss 0.5207 (0.5207)\tPrec 84.375% (84.375%)\n",
      " * Prec 86.750% \n",
      "best acc: 89.790000\n",
      "Epoch: [118][0/391]\tTime 0.393 (0.393)\tData 0.369 (0.369)\tLoss 0.0659 (0.0659)\tPrec 98.438% (98.438%)\n",
      "Epoch: [118][100/391]\tTime 0.020 (0.041)\tData 0.001 (0.005)\tLoss 0.1540 (0.0929)\tPrec 94.531% (96.976%)\n",
      "Epoch: [118][200/391]\tTime 0.044 (0.042)\tData 0.001 (0.004)\tLoss 0.0518 (0.0935)\tPrec 99.219% (96.980%)\n",
      "Epoch: [118][300/391]\tTime 0.044 (0.043)\tData 0.001 (0.003)\tLoss 0.0681 (0.0998)\tPrec 99.219% (96.709%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.287 (0.287)\tLoss 0.1926 (0.1926)\tPrec 92.969% (92.969%)\n",
      " * Prec 86.750% \n",
      "best acc: 89.790000\n",
      "Epoch: [119][0/391]\tTime 0.373 (0.373)\tData 0.308 (0.308)\tLoss 0.0584 (0.0584)\tPrec 98.438% (98.438%)\n",
      "Epoch: [119][100/391]\tTime 0.020 (0.045)\tData 0.001 (0.005)\tLoss 0.1268 (0.1014)\tPrec 96.094% (96.566%)\n",
      "Epoch: [119][200/391]\tTime 0.043 (0.042)\tData 0.001 (0.003)\tLoss 0.0353 (0.0987)\tPrec 99.219% (96.735%)\n",
      "Epoch: [119][300/391]\tTime 0.044 (0.042)\tData 0.001 (0.003)\tLoss 0.0600 (0.0969)\tPrec 98.438% (96.758%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.299 (0.299)\tLoss 0.3658 (0.3658)\tPrec 87.500% (87.500%)\n",
      " * Prec 88.380% \n",
      "best acc: 89.790000\n",
      "Epoch: [120][0/391]\tTime 0.411 (0.411)\tData 0.338 (0.338)\tLoss 0.0766 (0.0766)\tPrec 97.656% (97.656%)\n",
      "Epoch: [120][100/391]\tTime 0.041 (0.047)\tData 0.001 (0.006)\tLoss 0.1740 (0.1045)\tPrec 93.750% (96.419%)\n",
      "Epoch: [120][200/391]\tTime 0.043 (0.043)\tData 0.002 (0.004)\tLoss 0.0619 (0.1018)\tPrec 97.656% (96.529%)\n",
      "Epoch: [120][300/391]\tTime 0.043 (0.043)\tData 0.002 (0.003)\tLoss 0.1125 (0.1035)\tPrec 94.531% (96.527%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.2833 (0.2833)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.820% \n",
      "best acc: 89.790000\n",
      "Epoch: [121][0/391]\tTime 0.317 (0.317)\tData 0.286 (0.286)\tLoss 0.0663 (0.0663)\tPrec 96.875% (96.875%)\n",
      "Epoch: [121][100/391]\tTime 0.037 (0.046)\tData 0.001 (0.004)\tLoss 0.1108 (0.0944)\tPrec 96.094% (96.674%)\n",
      "Epoch: [121][200/391]\tTime 0.044 (0.043)\tData 0.002 (0.003)\tLoss 0.0286 (0.1003)\tPrec 99.219% (96.587%)\n",
      "Epoch: [121][300/391]\tTime 0.043 (0.043)\tData 0.001 (0.003)\tLoss 0.0777 (0.1028)\tPrec 97.656% (96.504%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 0.3429 (0.3429)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.810% \n",
      "best acc: 89.790000\n",
      "Epoch: [122][0/391]\tTime 0.426 (0.426)\tData 0.351 (0.351)\tLoss 0.1146 (0.1146)\tPrec 96.875% (96.875%)\n",
      "Epoch: [122][100/391]\tTime 0.043 (0.048)\tData 0.002 (0.006)\tLoss 0.0801 (0.0869)\tPrec 97.656% (97.053%)\n",
      "Epoch: [122][200/391]\tTime 0.043 (0.044)\tData 0.002 (0.004)\tLoss 0.0910 (0.0980)\tPrec 95.312% (96.661%)\n",
      "Epoch: [122][300/391]\tTime 0.046 (0.044)\tData 0.001 (0.003)\tLoss 0.1298 (0.1019)\tPrec 95.312% (96.548%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.295 (0.295)\tLoss 0.3525 (0.3525)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.720% \n",
      "best acc: 89.790000\n",
      "Epoch: [123][0/391]\tTime 0.349 (0.349)\tData 0.317 (0.317)\tLoss 0.0447 (0.0447)\tPrec 98.438% (98.438%)\n",
      "Epoch: [123][100/391]\tTime 0.037 (0.047)\tData 0.001 (0.005)\tLoss 0.0991 (0.0969)\tPrec 96.875% (96.604%)\n",
      "Epoch: [123][200/391]\tTime 0.043 (0.042)\tData 0.002 (0.005)\tLoss 0.1537 (0.0995)\tPrec 95.312% (96.564%)\n",
      "Epoch: [123][300/391]\tTime 0.043 (0.042)\tData 0.002 (0.004)\tLoss 0.1108 (0.0994)\tPrec 95.312% (96.551%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.281 (0.281)\tLoss 0.3759 (0.3759)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.790% \n",
      "best acc: 89.790000\n",
      "Epoch: [124][0/391]\tTime 0.374 (0.374)\tData 0.348 (0.348)\tLoss 0.0653 (0.0653)\tPrec 98.438% (98.438%)\n",
      "Epoch: [124][100/391]\tTime 0.044 (0.047)\tData 0.001 (0.005)\tLoss 0.0959 (0.1090)\tPrec 96.094% (96.349%)\n",
      "Epoch: [124][200/391]\tTime 0.044 (0.043)\tData 0.001 (0.003)\tLoss 0.0554 (0.1007)\tPrec 98.438% (96.560%)\n",
      "Epoch: [124][300/391]\tTime 0.043 (0.043)\tData 0.001 (0.002)\tLoss 0.1262 (0.0988)\tPrec 96.094% (96.639%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.2874 (0.2874)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.260% \n",
      "best acc: 89.790000\n",
      "Epoch: [125][0/391]\tTime 0.383 (0.383)\tData 0.355 (0.355)\tLoss 0.0947 (0.0947)\tPrec 96.094% (96.094%)\n",
      "Epoch: [125][100/391]\tTime 0.043 (0.046)\tData 0.002 (0.005)\tLoss 0.0596 (0.0986)\tPrec 97.656% (96.558%)\n",
      "Epoch: [125][200/391]\tTime 0.043 (0.043)\tData 0.001 (0.004)\tLoss 0.0883 (0.1029)\tPrec 97.656% (96.455%)\n",
      "Epoch: [125][300/391]\tTime 0.043 (0.043)\tData 0.001 (0.003)\tLoss 0.0964 (0.1001)\tPrec 98.438% (96.556%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.311 (0.311)\tLoss 0.3019 (0.3019)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.210% \n",
      "best acc: 89.790000\n",
      "Epoch: [126][0/391]\tTime 0.341 (0.341)\tData 0.316 (0.316)\tLoss 0.0729 (0.0729)\tPrec 97.656% (97.656%)\n",
      "Epoch: [126][100/391]\tTime 0.043 (0.046)\tData 0.001 (0.004)\tLoss 0.0387 (0.0893)\tPrec 99.219% (96.968%)\n",
      "Epoch: [126][200/391]\tTime 0.042 (0.043)\tData 0.002 (0.003)\tLoss 0.1057 (0.0935)\tPrec 98.438% (96.867%)\n",
      "Epoch: [126][300/391]\tTime 0.043 (0.043)\tData 0.001 (0.003)\tLoss 0.1099 (0.0968)\tPrec 95.312% (96.701%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.302 (0.302)\tLoss 0.3150 (0.3150)\tPrec 89.062% (89.062%)\n",
      " * Prec 88.530% \n",
      "best acc: 89.790000\n",
      "Epoch: [127][0/391]\tTime 0.415 (0.415)\tData 0.386 (0.386)\tLoss 0.0783 (0.0783)\tPrec 96.875% (96.875%)\n",
      "Epoch: [127][100/391]\tTime 0.043 (0.047)\tData 0.001 (0.005)\tLoss 0.1606 (0.0809)\tPrec 92.969% (97.192%)\n",
      "Epoch: [127][200/391]\tTime 0.043 (0.042)\tData 0.001 (0.004)\tLoss 0.0621 (0.0915)\tPrec 99.219% (96.856%)\n",
      "Epoch: [127][300/391]\tTime 0.043 (0.043)\tData 0.001 (0.003)\tLoss 0.0696 (0.0940)\tPrec 97.656% (96.795%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.2411 (0.2411)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.060% \n",
      "best acc: 89.790000\n",
      "Epoch: [128][0/391]\tTime 0.330 (0.330)\tData 0.301 (0.301)\tLoss 0.1418 (0.1418)\tPrec 93.750% (93.750%)\n",
      "Epoch: [128][100/391]\tTime 0.043 (0.046)\tData 0.001 (0.005)\tLoss 0.1499 (0.0861)\tPrec 92.969% (97.208%)\n",
      "Epoch: [128][200/391]\tTime 0.043 (0.043)\tData 0.002 (0.004)\tLoss 0.1667 (0.0955)\tPrec 93.750% (96.813%)\n",
      "Epoch: [128][300/391]\tTime 0.045 (0.043)\tData 0.001 (0.003)\tLoss 0.1323 (0.0975)\tPrec 93.750% (96.722%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.3068 (0.3068)\tPrec 89.062% (89.062%)\n",
      " * Prec 89.230% \n",
      "best acc: 89.790000\n",
      "Epoch: [129][0/391]\tTime 0.367 (0.367)\tData 0.340 (0.340)\tLoss 0.1697 (0.1697)\tPrec 93.750% (93.750%)\n",
      "Epoch: [129][100/391]\tTime 0.043 (0.046)\tData 0.002 (0.005)\tLoss 0.0842 (0.0903)\tPrec 96.875% (96.921%)\n",
      "Epoch: [129][200/391]\tTime 0.044 (0.043)\tData 0.001 (0.004)\tLoss 0.1182 (0.0957)\tPrec 96.875% (96.696%)\n",
      "Epoch: [129][300/391]\tTime 0.043 (0.043)\tData 0.001 (0.003)\tLoss 0.1237 (0.0969)\tPrec 96.875% (96.613%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.1888 (0.1888)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.950% \n",
      "best acc: 89.950000\n",
      "Epoch: [130][0/391]\tTime 0.340 (0.340)\tData 0.309 (0.309)\tLoss 0.0876 (0.0876)\tPrec 96.875% (96.875%)\n",
      "Epoch: [130][100/391]\tTime 0.043 (0.046)\tData 0.002 (0.005)\tLoss 0.0644 (0.0926)\tPrec 97.656% (96.674%)\n",
      "Epoch: [130][200/391]\tTime 0.018 (0.041)\tData 0.001 (0.003)\tLoss 0.1866 (0.0929)\tPrec 93.750% (96.739%)\n",
      "Epoch: [130][300/391]\tTime 0.043 (0.042)\tData 0.002 (0.003)\tLoss 0.1128 (0.0949)\tPrec 96.875% (96.706%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.4803 (0.4803)\tPrec 86.719% (86.719%)\n",
      " * Prec 86.770% \n",
      "best acc: 89.950000\n",
      "Epoch: [131][0/391]\tTime 0.402 (0.402)\tData 0.335 (0.335)\tLoss 0.0596 (0.0596)\tPrec 99.219% (99.219%)\n",
      "Epoch: [131][100/391]\tTime 0.043 (0.047)\tData 0.001 (0.005)\tLoss 0.1014 (0.0857)\tPrec 95.312% (97.138%)\n",
      "Epoch: [131][200/391]\tTime 0.018 (0.044)\tData 0.001 (0.003)\tLoss 0.0706 (0.0923)\tPrec 96.875% (96.891%)\n",
      "Epoch: [131][300/391]\tTime 0.043 (0.044)\tData 0.001 (0.003)\tLoss 0.0545 (0.0979)\tPrec 99.219% (96.649%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.296 (0.296)\tLoss 0.2797 (0.2797)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.290% \n",
      "best acc: 89.950000\n",
      "Epoch: [132][0/391]\tTime 0.333 (0.333)\tData 0.309 (0.309)\tLoss 0.1077 (0.1077)\tPrec 98.438% (98.438%)\n",
      "Epoch: [132][100/391]\tTime 0.037 (0.046)\tData 0.002 (0.005)\tLoss 0.0594 (0.0970)\tPrec 98.438% (96.720%)\n",
      "Epoch: [132][200/391]\tTime 0.021 (0.045)\tData 0.001 (0.003)\tLoss 0.1344 (0.0988)\tPrec 96.875% (96.603%)\n",
      "Epoch: [132][300/391]\tTime 0.043 (0.044)\tData 0.001 (0.002)\tLoss 0.0713 (0.1002)\tPrec 98.438% (96.558%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.304 (0.304)\tLoss 0.2875 (0.2875)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.910% \n",
      "best acc: 89.950000\n",
      "Epoch: [133][0/391]\tTime 0.330 (0.330)\tData 0.302 (0.302)\tLoss 0.0610 (0.0610)\tPrec 97.656% (97.656%)\n",
      "Epoch: [133][100/391]\tTime 0.044 (0.046)\tData 0.001 (0.005)\tLoss 0.0588 (0.0889)\tPrec 99.219% (97.130%)\n",
      "Epoch: [133][200/391]\tTime 0.021 (0.044)\tData 0.001 (0.003)\tLoss 0.1125 (0.0908)\tPrec 96.094% (97.023%)\n",
      "Epoch: [133][300/391]\tTime 0.043 (0.044)\tData 0.001 (0.003)\tLoss 0.0847 (0.0936)\tPrec 96.094% (96.859%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 0.2765 (0.2765)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.080% \n",
      "best acc: 89.950000\n",
      "Epoch: [134][0/391]\tTime 0.406 (0.406)\tData 0.379 (0.379)\tLoss 0.2234 (0.2234)\tPrec 93.750% (93.750%)\n",
      "Epoch: [134][100/391]\tTime 0.045 (0.046)\tData 0.002 (0.005)\tLoss 0.0569 (0.0904)\tPrec 99.219% (97.061%)\n",
      "Epoch: [134][200/391]\tTime 0.040 (0.044)\tData 0.002 (0.003)\tLoss 0.0681 (0.0924)\tPrec 96.875% (96.914%)\n",
      "Epoch: [134][300/391]\tTime 0.043 (0.043)\tData 0.001 (0.003)\tLoss 0.1943 (0.0978)\tPrec 93.750% (96.727%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.288 (0.288)\tLoss 0.2277 (0.2277)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.700% \n",
      "best acc: 89.950000\n",
      "Epoch: [135][0/391]\tTime 0.421 (0.421)\tData 0.389 (0.389)\tLoss 0.0600 (0.0600)\tPrec 98.438% (98.438%)\n",
      "Epoch: [135][100/391]\tTime 0.044 (0.046)\tData 0.001 (0.005)\tLoss 0.1197 (0.0881)\tPrec 96.094% (96.976%)\n",
      "Epoch: [135][200/391]\tTime 0.037 (0.044)\tData 0.001 (0.003)\tLoss 0.2732 (0.0917)\tPrec 91.406% (96.926%)\n",
      "Epoch: [135][300/391]\tTime 0.043 (0.042)\tData 0.002 (0.003)\tLoss 0.1160 (0.0980)\tPrec 95.312% (96.696%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.1211 (0.1211)\tPrec 96.875% (96.875%)\n",
      " * Prec 89.020% \n",
      "best acc: 89.950000\n",
      "Epoch: [136][0/391]\tTime 0.416 (0.416)\tData 0.387 (0.387)\tLoss 0.0531 (0.0531)\tPrec 98.438% (98.438%)\n",
      "Epoch: [136][100/391]\tTime 0.043 (0.047)\tData 0.002 (0.005)\tLoss 0.0853 (0.0949)\tPrec 96.094% (96.689%)\n",
      "Epoch: [136][200/391]\tTime 0.098 (0.046)\tData 0.002 (0.004)\tLoss 0.0436 (0.0924)\tPrec 96.875% (96.813%)\n",
      "Epoch: [136][300/391]\tTime 0.043 (0.043)\tData 0.001 (0.003)\tLoss 0.0886 (0.0955)\tPrec 97.656% (96.737%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.2024 (0.2024)\tPrec 95.312% (95.312%)\n",
      " * Prec 88.810% \n",
      "best acc: 89.950000\n",
      "Epoch: [137][0/391]\tTime 0.396 (0.396)\tData 0.371 (0.371)\tLoss 0.1429 (0.1429)\tPrec 94.531% (94.531%)\n",
      "Epoch: [137][100/391]\tTime 0.041 (0.047)\tData 0.002 (0.005)\tLoss 0.0919 (0.0931)\tPrec 96.875% (96.612%)\n",
      "Epoch: [137][200/391]\tTime 0.044 (0.045)\tData 0.001 (0.003)\tLoss 0.1068 (0.0950)\tPrec 98.438% (96.685%)\n",
      "Epoch: [137][300/391]\tTime 0.043 (0.043)\tData 0.002 (0.003)\tLoss 0.0458 (0.0964)\tPrec 96.875% (96.737%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 0.2970 (0.2970)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.390% \n",
      "best acc: 89.950000\n",
      "Epoch: [138][0/391]\tTime 0.429 (0.429)\tData 0.402 (0.402)\tLoss 0.0991 (0.0991)\tPrec 96.875% (96.875%)\n",
      "Epoch: [138][100/391]\tTime 0.043 (0.047)\tData 0.001 (0.005)\tLoss 0.0995 (0.0969)\tPrec 98.438% (96.481%)\n",
      "Epoch: [138][200/391]\tTime 0.044 (0.045)\tData 0.001 (0.003)\tLoss 0.1203 (0.0973)\tPrec 97.656% (96.615%)\n",
      "Epoch: [138][300/391]\tTime 0.043 (0.043)\tData 0.002 (0.003)\tLoss 0.1376 (0.0991)\tPrec 95.312% (96.561%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.312 (0.312)\tLoss 0.1748 (0.1748)\tPrec 96.094% (96.094%)\n",
      " * Prec 88.700% \n",
      "best acc: 89.950000\n",
      "Epoch: [139][0/391]\tTime 0.339 (0.339)\tData 0.312 (0.312)\tLoss 0.0838 (0.0838)\tPrec 96.875% (96.875%)\n",
      "Epoch: [139][100/391]\tTime 0.043 (0.046)\tData 0.002 (0.005)\tLoss 0.0574 (0.0836)\tPrec 98.438% (97.355%)\n",
      "Epoch: [139][200/391]\tTime 0.043 (0.044)\tData 0.002 (0.003)\tLoss 0.1125 (0.0895)\tPrec 94.531% (97.100%)\n",
      "Epoch: [139][300/391]\tTime 0.153 (0.043)\tData 0.001 (0.003)\tLoss 0.1112 (0.0945)\tPrec 97.656% (96.870%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.1879 (0.1879)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.190% \n",
      "best acc: 90.190000\n",
      "Epoch: [140][0/391]\tTime 0.367 (0.367)\tData 0.306 (0.306)\tLoss 0.0599 (0.0599)\tPrec 98.438% (98.438%)\n",
      "Epoch: [140][100/391]\tTime 0.043 (0.046)\tData 0.002 (0.005)\tLoss 0.0838 (0.0744)\tPrec 98.438% (97.602%)\n",
      "Epoch: [140][200/391]\tTime 0.043 (0.045)\tData 0.002 (0.003)\tLoss 0.1659 (0.0867)\tPrec 96.875% (97.023%)\n",
      "Epoch: [140][300/391]\tTime 0.046 (0.043)\tData 0.001 (0.003)\tLoss 0.0499 (0.0929)\tPrec 97.656% (96.831%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.2185 (0.2185)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.510% \n",
      "best acc: 90.190000\n",
      "Epoch: [141][0/391]\tTime 0.394 (0.394)\tData 0.365 (0.365)\tLoss 0.0658 (0.0658)\tPrec 99.219% (99.219%)\n",
      "Epoch: [141][100/391]\tTime 0.044 (0.047)\tData 0.001 (0.005)\tLoss 0.1315 (0.0873)\tPrec 95.312% (96.991%)\n",
      "Epoch: [141][200/391]\tTime 0.044 (0.045)\tData 0.001 (0.003)\tLoss 0.0538 (0.0918)\tPrec 98.438% (96.809%)\n",
      "Epoch: [141][300/391]\tTime 0.020 (0.043)\tData 0.001 (0.003)\tLoss 0.1841 (0.0965)\tPrec 95.312% (96.717%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.2640 (0.2640)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.960% \n",
      "best acc: 90.190000\n",
      "Epoch: [142][0/391]\tTime 0.441 (0.441)\tData 0.414 (0.414)\tLoss 0.1330 (0.1330)\tPrec 96.094% (96.094%)\n",
      "Epoch: [142][100/391]\tTime 0.043 (0.047)\tData 0.002 (0.006)\tLoss 0.0493 (0.0876)\tPrec 98.438% (97.123%)\n",
      "Epoch: [142][200/391]\tTime 0.043 (0.045)\tData 0.002 (0.004)\tLoss 0.0599 (0.0875)\tPrec 98.438% (97.023%)\n",
      "Epoch: [142][300/391]\tTime 0.021 (0.044)\tData 0.002 (0.003)\tLoss 0.1544 (0.0906)\tPrec 96.094% (96.935%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.314 (0.314)\tLoss 0.3384 (0.3384)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.440% \n",
      "best acc: 90.190000\n",
      "Epoch: [143][0/391]\tTime 0.391 (0.391)\tData 0.361 (0.361)\tLoss 0.1284 (0.1284)\tPrec 95.312% (95.312%)\n",
      "Epoch: [143][100/391]\tTime 0.043 (0.047)\tData 0.002 (0.005)\tLoss 0.1297 (0.0908)\tPrec 94.531% (96.883%)\n",
      "Epoch: [143][200/391]\tTime 0.045 (0.045)\tData 0.002 (0.003)\tLoss 0.0368 (0.0940)\tPrec 98.438% (96.859%)\n",
      "Epoch: [143][300/391]\tTime 0.019 (0.044)\tData 0.002 (0.003)\tLoss 0.0341 (0.0931)\tPrec 98.438% (96.839%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.295 (0.295)\tLoss 0.3183 (0.3183)\tPrec 89.844% (89.844%)\n",
      " * Prec 89.360% \n",
      "best acc: 90.190000\n",
      "Epoch: [144][0/391]\tTime 0.326 (0.326)\tData 0.299 (0.299)\tLoss 0.0713 (0.0713)\tPrec 96.875% (96.875%)\n",
      "Epoch: [144][100/391]\tTime 0.043 (0.046)\tData 0.001 (0.004)\tLoss 0.0971 (0.0894)\tPrec 96.094% (96.898%)\n",
      "Epoch: [144][200/391]\tTime 0.044 (0.045)\tData 0.001 (0.003)\tLoss 0.0452 (0.0959)\tPrec 97.656% (96.727%)\n",
      "Epoch: [144][300/391]\tTime 0.019 (0.044)\tData 0.001 (0.002)\tLoss 0.0326 (0.0963)\tPrec 99.219% (96.675%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.2809 (0.2809)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.050% \n",
      "best acc: 90.190000\n",
      "Epoch: [145][0/391]\tTime 0.441 (0.441)\tData 0.413 (0.413)\tLoss 0.0677 (0.0677)\tPrec 99.219% (99.219%)\n",
      "Epoch: [145][100/391]\tTime 0.041 (0.047)\tData 0.001 (0.006)\tLoss 0.0374 (0.0881)\tPrec 99.219% (96.999%)\n",
      "Epoch: [145][200/391]\tTime 0.046 (0.045)\tData 0.001 (0.003)\tLoss 0.1081 (0.0903)\tPrec 95.312% (96.875%)\n",
      "Epoch: [145][300/391]\tTime 0.024 (0.044)\tData 0.001 (0.003)\tLoss 0.0284 (0.0939)\tPrec 99.219% (96.795%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.307 (0.307)\tLoss 0.2079 (0.2079)\tPrec 95.312% (95.312%)\n",
      " * Prec 89.630% \n",
      "best acc: 90.190000\n",
      "Epoch: [146][0/391]\tTime 0.409 (0.409)\tData 0.384 (0.384)\tLoss 0.0962 (0.0962)\tPrec 96.094% (96.094%)\n",
      "Epoch: [146][100/391]\tTime 0.043 (0.047)\tData 0.001 (0.005)\tLoss 0.0891 (0.0905)\tPrec 96.094% (96.921%)\n",
      "Epoch: [146][200/391]\tTime 0.044 (0.045)\tData 0.001 (0.003)\tLoss 0.1063 (0.0917)\tPrec 96.875% (96.840%)\n",
      "Epoch: [146][300/391]\tTime 0.037 (0.045)\tData 0.001 (0.003)\tLoss 0.1336 (0.0933)\tPrec 96.094% (96.789%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.292 (0.292)\tLoss 0.2147 (0.2147)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.670% \n",
      "best acc: 90.190000\n",
      "Epoch: [147][0/391]\tTime 0.413 (0.413)\tData 0.384 (0.384)\tLoss 0.1132 (0.1132)\tPrec 96.875% (96.875%)\n",
      "Epoch: [147][100/391]\tTime 0.044 (0.047)\tData 0.001 (0.005)\tLoss 0.0812 (0.0922)\tPrec 96.094% (96.829%)\n",
      "Epoch: [147][200/391]\tTime 0.043 (0.045)\tData 0.001 (0.003)\tLoss 0.0908 (0.0940)\tPrec 96.875% (96.778%)\n",
      "Epoch: [147][300/391]\tTime 0.046 (0.045)\tData 0.001 (0.003)\tLoss 0.1021 (0.0968)\tPrec 97.656% (96.678%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.309 (0.309)\tLoss 0.1869 (0.1869)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.360% \n",
      "best acc: 90.190000\n",
      "Epoch: [148][0/391]\tTime 0.315 (0.315)\tData 0.285 (0.285)\tLoss 0.1244 (0.1244)\tPrec 96.094% (96.094%)\n",
      "Epoch: [148][100/391]\tTime 0.044 (0.046)\tData 0.001 (0.004)\tLoss 0.1064 (0.0855)\tPrec 96.094% (97.161%)\n",
      "Epoch: [148][200/391]\tTime 0.044 (0.044)\tData 0.001 (0.003)\tLoss 0.0682 (0.0869)\tPrec 98.438% (97.139%)\n",
      "Epoch: [148][300/391]\tTime 0.041 (0.044)\tData 0.001 (0.002)\tLoss 0.0596 (0.0907)\tPrec 98.438% (96.976%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.2947 (0.2947)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.930% \n",
      "best acc: 90.190000\n",
      "Epoch: [149][0/391]\tTime 0.386 (0.386)\tData 0.305 (0.305)\tLoss 0.1028 (0.1028)\tPrec 96.094% (96.094%)\n",
      "Epoch: [149][100/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.0734 (0.0884)\tPrec 97.656% (97.107%)\n",
      "Epoch: [149][200/391]\tTime 0.043 (0.045)\tData 0.001 (0.003)\tLoss 0.1176 (0.0851)\tPrec 96.094% (97.120%)\n",
      "Epoch: [149][300/391]\tTime 0.043 (0.044)\tData 0.002 (0.003)\tLoss 0.1029 (0.0889)\tPrec 95.312% (96.935%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.3260 (0.3260)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.730% \n",
      "best acc: 90.190000\n"
     ]
    }
   ],
   "source": [
    "# This cell won't be given, but students will complete the training\n",
    "\n",
    "lr = 1e-2\n",
    "weight_decay = 8e-4\n",
    "epochs = 150\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "untrained = True\n",
    "\n",
    "if (untrained):\n",
    "    for epoch in range(0, epochs):\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "    \n",
    "        train(trainloader, model, criterion, optimizer, epoch)\n",
    "        \n",
    "        # evaluate on test set\n",
    "        print(\"Validation starts\")\n",
    "        prec = validate(testloader, model, criterion)\n",
    "    \n",
    "        # remember best precision and save checkpoint\n",
    "        is_best = prec > best_prec\n",
    "        best_prec = max(prec,best_prec)\n",
    "        print('best acc: {:1f}'.format(best_prec))\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec': best_prec,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "corresponding-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW\n",
    "\n",
    "#  1. Train with 4 bits for both weight and activation to achieve >90% accuracy\n",
    "#  2. Find x_int and w_int for the 2nd convolution layer\n",
    "#  3. Check the recovered psum has similar value to the un-quantized original psum\n",
    "#     (such as example 1 in W3S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9019/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/final_VGG16_quant/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "#send an input and grap the value by using prehook like HW3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minimal-serbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "prehooked\n",
      "1st convolution's input size: torch.Size([128, 3, 32, 32])\n",
      "2nd convolution's input size: torch.Size([128, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        print(\"prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)       ## Input for the module will be grapped       \n",
    "####################################################\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\") \n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)\n",
    "\n",
    "print(\"1st convolution's input size:\", save_output.outputs[0][0].size())\n",
    "print(\"2nd convolution's input size:\", save_output.outputs[1][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abbfe575-83b0-46a2-a227-09fb38ade009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: torch.Size([128, 3, 32, 32])\n",
      "1: torch.Size([128, 64, 32, 32])\n",
      "2: torch.Size([128, 64, 16, 16])\n",
      "3: torch.Size([128, 128, 16, 16])\n",
      "4: torch.Size([128, 128, 8, 8])\n",
      "5: torch.Size([128, 256, 8, 8])\n",
      "6: torch.Size([128, 256, 8, 8])\n",
      "7: torch.Size([128, 256, 4, 4])\n",
      "8: torch.Size([128, 8, 4, 4])\n",
      "9: torch.Size([128, 8, 4, 4])\n",
      "10: torch.Size([128, 512, 2, 2])\n",
      "11: torch.Size([128, 512, 2, 2])\n",
      "12: torch.Size([128, 512, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(save_output.outputs)):\n",
    "    print(str(index) + \": \" + str(save_output.outputs[index][0].size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b340c2e8-bef8-460a-a2d2-0b2024f7de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_bit = 4\n",
    "weight_q = model.features[27].weight_q # quantized value is stored during the training\n",
    "w_alpha = model.features[27].weight_quant.wgt_alpha  # alpha is defined in your model already. bring it out here\n",
    "w_delta = w_alpha / (2**(w_bit-1)-1)    # delta can be calculated by using alpha and w_bit\n",
    "weight_int = weight_q / w_delta # w_int can be calculated by weight_q and w_delta\n",
    "#print(weight_int) # you should see clean integer numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2856498d-ee72-4845-a6f6-c897016dcd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bit = 4    \n",
    "x = save_output.outputs[8][0]  # input of the 2nd conv layer\n",
    "x_alpha  = model.features[27].act_alpha\n",
    "x_delta = x_alpha / (2**(x_bit)-1)\n",
    "\n",
    "act_quant_fn = act_quantization(x_bit) # define the quantization function\n",
    "x_q = act_quant_fn(x, x_alpha)         # create the quantized value for x\n",
    "\n",
    "x_int = x_q / x_delta\n",
    "#print(x_int) # you should see clean integer numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee383a5e-6d25-4b1d-aee9-8384c882db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1, bias = False)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "\n",
    "output_int =  conv_int.forward(x_int)    # output_int can be calculated with conv_int and x_int\n",
    "output_recovered = output_int * x_delta * w_delta  # recover with x_delta and w_delta\n",
    "\n",
    "relu = torch.nn.ReLU()\n",
    "relu_output_recovered = relu(output_recovered)\n",
    "#print(output_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a59e9c3-a95b-4586-bee3-c9021713d534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8, 4, 4])\n",
      "torch.Size([128, 8, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "next_input = save_output.outputs[9][0]\n",
    "\n",
    "print(next_input.size())\n",
    "print(relu_output_recovered.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5f273e6-12ae-44e4-8401-7f95dc408a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1711e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "difference = abs( next_input - relu_output_recovered )\n",
    "print(difference.mean())  ## It should be small, e.g.,2.3 in my trainned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb8472ca-12ee-4a0c-a201-dfaacbe873c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x_int[0,:,:,:].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cebbc32c-899b-4b27-9ad4-c3289c30dedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x_int.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bb6ebee-1879-4180-892c-9f3043afbe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# act_int.size = torch.Size([128, 64, 32, 32])  <- batch_size, input_ch, ni, nj\n",
    "a_int = x_int[0,:,:,:]  # pick only one input out of batch\n",
    "# a_int.size() = [64, 32, 32]\n",
    "\n",
    "# conv_int.weight.size() = torch.Size([64, 64, 3, 3])  <- output_ch, input_ch, ki, kj\n",
    "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))  # merge ki, kj index to kij\n",
    "# w_int.weight.size() = torch.Size([64, 64, 9])\n",
    "                      \n",
    "padding = 1\n",
    "stride = 1\n",
    "array_size = 8 # row and column number\n",
    "\n",
    "nig = range(a_int.size(1))  ## ni group\n",
    "njg = range(a_int.size(2))  ## nj group\n",
    "\n",
    "icg = range(int(w_int.size(1)))  ## input channel \n",
    "ocg = range(int(w_int.size(0)))  ## output channel\n",
    "\n",
    "ic_tileg = range(int(len(icg)/array_size))\n",
    "oc_tileg = range(int(len(ocg)/array_size))\n",
    "\n",
    "kijg = range(w_int.size(2))\n",
    "ki_dim = int(math.sqrt(w_int.size(2)))  ## Kernel's 1 dim size\n",
    "\n",
    "######## Padding before Convolution #######\n",
    "a_pad = torch.zeros(len(icg), len(nig)+padding*2, len(nig)+padding*2).cuda()\n",
    "# a_pad.size() = [64, 32+2pad, 32+2pad]\n",
    "a_pad[ :, padding:padding+len(nig), padding:padding+len(njg)] = a_int.cuda()\n",
    "a_pad = torch.reshape(a_pad, (a_pad.size(0), -1))\n",
    "# a_pad.size() = [64, (32+2pad)*(32+2pad)]\n",
    "\n",
    "\n",
    "a_tile = torch.zeros(len(ic_tileg), array_size,    a_pad.size(1)).cuda() \n",
    "w_tile = torch.zeros(len(oc_tileg)*len(ic_tileg), array_size, array_size, len(kijg)).cuda() \n",
    "\n",
    "for ic_tile in ic_tileg:\n",
    "    a_tile[ic_tile,:,:] = a_pad[ic_tile*array_size:(ic_tile+1)*array_size,:]\n",
    "\n",
    "for ic_tile in ic_tileg:\n",
    "    for oc_tile in oc_tileg:\n",
    "        w_tile[oc_tile*len(oc_tileg) + ic_tile,:,:,:] = w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, :]\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "p_nijg = range(a_pad.size(1)) ## psum nij group\n",
    "\n",
    "psum = torch.zeros(len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)).cuda() \n",
    "\n",
    "for kij in kijg:\n",
    "    for ic_tile in ic_tileg:       # Tiling into array_sizeXarray_size array\n",
    "        for oc_tile in oc_tileg:   # Tiling into array_sizeXarray_size array        \n",
    "            for nij in p_nijg:       # time domain, sequentially given input\n",
    "                    m = nn.Linear(array_size, array_size, bias=False)\n",
    "                    #m.weight = torch.nn.Parameter(w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, kij])\n",
    "                    m.weight = torch.nn.Parameter(w_tile[len(oc_tileg)*oc_tile+ic_tile,:,:,kij])\n",
    "                    psum[ic_tile, oc_tile, :, nij, kij] = m(a_tile[ic_tile,:,nij]).cuda()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd577acd-420e-48ac-89ea-6dcf6312c151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 36])\n",
      "torch.Size([1, 1, 8, 36, 9])\n"
     ]
    }
   ],
   "source": [
    "print(a_tile.size())\n",
    "print(psum.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a54a6afb-0927-43fd-a5b5-cdfcfe6e6fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "a_pad_ni_dim = int(math.sqrt(a_pad.size(1))) # 32\n",
    "\n",
    "o_ni_dim = int((a_pad_ni_dim - (ki_dim- 1) - 1)/stride + 1)\n",
    "o_nijg = range(o_ni_dim**2)    \n",
    "\n",
    "print(len(o_nijg))\n",
    "\n",
    "out = torch.zeros(len(ocg), len(o_nijg)).cuda()\n",
    "  \n",
    "   \n",
    "### SFP accumulation ###\n",
    "for o_nij in o_nijg: \n",
    "    for kij in kijg:\n",
    "        for ic_tile in ic_tileg:    \n",
    "            for oc_tile in oc_tileg:   \n",
    "                out[oc_tile*array_size:(oc_tile+1)*array_size, o_nij] = out[oc_tile*array_size:(oc_tile+1)*array_size, o_nij] + \\\n",
    "                psum[ic_tile, oc_tile, :, int(o_nij/o_ni_dim)*a_pad_ni_dim + o_nij%o_ni_dim + int(kij/ki_dim)*a_pad_ni_dim + kij%ki_dim, kij]\n",
    "                ## 4th index = (int(o_nij/30)*32 + o_nij%30) + (int(kij/3)*32 + kij%3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "761db8ee-ed6f-4efc-9340-aed515a8524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(o_ni_dim)\n",
    "print(a_pad_ni_dim)\n",
    "print(ki_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b4d3777-6e26-4d4f-bb7b-9db6e86c084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-7.0000, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-7.0000, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-7.0000, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(2., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-7.0000, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(6., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-7.0000, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(7.0000, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(11.0000, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(7.0000, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-7.0000, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(21.0000, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "temp_acc = 0\n",
    "for row in range(8):\n",
    "    for col in range(1):\n",
    "        print(a_tile[0,row,7])\n",
    "        print(w_tile[0,col,row,0])\n",
    "        temp_acc = temp_acc + a_tile[0,row,7] * w_tile[0, col, row, 0]\n",
    "print(temp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "488cc825-58f9-42a1-b87a-0a82eb139a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### show this cell partially. The following cells should be printed by students ###\n",
    "tile_id = 0 \n",
    "nij = 200 # just a random number\n",
    "X = a_tile[tile_id,:,:]  # [tile_num, array row num, time_steps]\n",
    "\n",
    "bit_precision = 4\n",
    "file = open('activation.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:04b}'.format(round(X[X.size(0)-1-j,i].item()))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c18ac114-f744-447f-8f0e-f44296db0a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete this cell ###\n",
    "tile_id = 0 \n",
    "kij = 0\n",
    "\n",
    "\n",
    "bit_precision = 4\n",
    "for kij in range(9):\n",
    "    W = w_tile[tile_id,:,:,kij]  # w_tile[tile_num, array col num, array row num, kij]\n",
    "    file = open('weight_' + str(kij) + '.txt', 'w') #write to file\n",
    "    file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "    file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "    file.write('#................#\\n')\n",
    "    \n",
    "    for i in range(W.size(1)):  # col\n",
    "        for j in range(W.size(0)): # row #\n",
    "            W_bin = '{0:04b}'.format(round(W[i,7-j].item()) + (16 if (round(W[i,7-j].item()) < 0) else 0))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(W_bin[k])        \n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "    file.close() #close file   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dfa2352-d11d-4537-83a1-d03b37dd1302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-21\n",
      "-000000000010101\n",
      "1111111111101011\n",
      "21\n",
      "-49\n",
      "-000000000110001\n",
      "1111111111001111\n",
      "-105\n",
      "-000000001101001\n",
      "1111111110010111\n",
      "-21\n",
      "-000000000010101\n",
      "1111111111101011\n",
      "105\n",
      "-105\n",
      "-000000001101001\n",
      "1111111110010111\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "### Complete this cell ###\n",
    "ic_tile_id = 0 \n",
    "oc_tile_id = 0 \n",
    "\n",
    "\n",
    "kij = 0\n",
    "nij = 200\n",
    "# psum[len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)]\n",
    "\n",
    "\n",
    "bit_precision = 16\n",
    "\n",
    "for kij in range(9):\n",
    "    psum_tile = psum[ic_tile_id,oc_tile_id,:,:,kij]  \n",
    "    file = open('psum_' + str(kij) + '.txt', 'w') #write to file\n",
    "    file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "    file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "    file.write('#................#\\n')\n",
    "\n",
    "    for i in range(psum_tile.size(1)):  # time step\n",
    "        for j in range(psum_tile.size(0)): # col #\n",
    "            #psum_bin = '{0:016b}'.format(round(psum_tile[psum_tile.size(0)-1-j,i].item()) + (2**bit_precision if (round(psum_tile[psum_tile.size(0)-1-j,i].item()) < 0) else 0))\n",
    "            curr_psum = round(psum_tile[psum_tile.size(0)-1-j,i].item())\n",
    "            if (i == 7 and kij == 0):\n",
    "                print(curr_psum)\n",
    "            if (curr_psum < 0):\n",
    "                if (i == 7 and kij == 0):\n",
    "                    print('{0:016b}'.format(curr_psum))\n",
    "                curr_psum = curr_psum + 2**bit_precision\n",
    "                if (i == 7 and kij == 0):\n",
    "                    print('{0:016b}'.format(curr_psum))\n",
    "            psum_bin = '{0:016b}'.format(curr_psum)\n",
    "            \n",
    "            for k in range(bit_precision):\n",
    "                file.write(psum_bin[k])        \n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "    file.close() #close file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49a77564-a1b3-4abc-8eda-f725245e8271",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete this cell ###\n",
    "\n",
    "\n",
    "bit_precision = 16\n",
    "# out is array of size columns x len(o_nijg)\n",
    "\n",
    "file = open('out.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(out.size(1)):  # time step\n",
    "    for j in range(out.size(0)): # row #\n",
    "        out_bin = '{0:016b}'.format(0 if (round(out[out.size(0)-1-j,i].item()) < 0) else (round(out[out.size(0)-1-j,i].item())))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(out_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2b98243-6d02-47d8-b4cd-2827858306a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 273.0000,  154.0000,  182.0000,  147.0000,  308.0000,  363.9999,\n",
      "         154.0000,  252.0000,   49.0000,  133.0000,   77.0000,  -63.0000,\n",
      "         -84.0000, -329.0000, -238.0000, -210.0000], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f78b6e98-7fac-45af-94a6-a55dbfaeaec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 273.0000,  154.0000,  182.0000,  147.0000,  308.0000,  363.9999,\n",
      "         154.0000,  252.0000,   49.0000,  133.0000,   77.0000,  -63.0000,\n",
      "         -84.0000, -329.0000, -238.0000, -210.0000], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc0c43be-e3cc-48cd-aea4-3299dfc8c3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 36])\n"
     ]
    }
   ],
   "source": [
    "print(X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f444b800-6f5d-4021-b0fc-c64554f74f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(o_ni_dim)\n",
    "print(a_pad_ni_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67374d1f-8595-421c-b91c-5058f363e0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(weight_int.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cfb764-d2d9-41df-ae92-414d586618f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09339ec1-6acc-4ef0-97b7-d74d8ffd32f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58d38d-7437-4b6e-b017-539f14dbb6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
